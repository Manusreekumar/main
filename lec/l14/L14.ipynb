{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS579\n",
    "### Logistic Regression\n",
    "\n",
    "<br><br>\n",
    "#### Illinois Institute of Technology  \n",
    "#### Aron Culotta\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification problem notation:\n",
    "\n",
    "\n",
    "- $\\vec{x} \\in \\mathcal{X}$ &nbsp;&nbsp;&nbsp;&nbsp; *instance*, *example*, *input*\n",
    "  - e.g., an email, a sentence\n",
    "  \n",
    "- $y \\in \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *target*, *class*, *label*, *output*\n",
    "  - e.g., $y=1$: spam ; $y=-1$: not spam\n",
    "  \n",
    "- $f: \\mathcal{X} \\mapsto \\mathcal{Y}$ &nbsp;&nbsp;&nbsp;&nbsp; *hypothesis*, *learner*, *model*, *classifier*\n",
    "  - e.g., if $x$ contain the word *free*, $y$ is $1$.\n",
    "  \n",
    "  \n",
    "Main quantity of interest: $p(y \\mid \\vec{x})$,  \n",
    "the probability of a class label $y$ given a feature vector $\\vec{x}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised classification\n",
    "\n",
    "We are given **training data** $D = \\{(\\vec{x}_1, y_1), \\ldots, (\\vec{x}_n, y_n)\\}$\n",
    "\n",
    "||free|money| |*label*|\n",
    "|:--:|:--------:|:--------:|:--:|:--:|\n",
    "||$x_{i1}$|$x_{i2}$| | $y_i$ |\n",
    "|$x_1$|0|0||-1| \n",
    "|$x_2$|1|0|| 1|\n",
    "|$x_3$|1|1||-1|\n",
    "|$x_4$|1|0||-1|\n",
    "|$x_5$|1|1||1|\n",
    "|$x_6$|0|0||1|\n",
    "|$x_7$|0|1||-1|\n",
    "\n",
    "How to classify a new instance?  \n",
    " \"free money\" -> $\\{1,1\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<u> How can we estimate</u> $p(y \\mid \\vec{x})$?\n",
    "\n",
    "<br><br><br>\n",
    "\n",
    "#### Function estimation\n",
    "\n",
    "$p(y \\mid \\vec{x})$ is just a function $f(y, \\vec{x})$ that satisfies three criteria:\n",
    "1. $0 \\le f(y, \\vec{x}) \\le 1$  : values are between 0 and 1\n",
    "2. $\\sum_{y_i} f(y_i, \\vec{x}) = 1$  : values sum to one for all possible classes\n",
    "3. If $f(y_i, \\vec{x}) > f(y_j, \\vec{x})$, then it is more likely that $\\vec{x}$ is of class $i$ than of class $j$\n",
    "\n",
    "\n",
    "How do we ensure criterion 3?\n",
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification as a type of regression\n",
    "\n",
    "Assume our function has some real-valued parameter vector $\\vec{\\theta} = \\{\\theta_1 \\ldots \\theta_k\\}$\n",
    "\n",
    "For simplicity, let's assume there are $k$ terms in our vocabulary, and that each $\\theta$ is associated with a single term.\n",
    "\n",
    "Further, let's assume binary classification, where $y \\in \\{-1, 1\\}$.\n",
    "\n",
    "One simple way to construct a function is as follows:\n",
    "\n",
    "$f(\\vec{x}, \\vec{\\theta}) = \\sum_j x_j \\theta_j = \\vec{x} \\cdot \\vec{\\theta}$  \n",
    "where  \n",
    "- $x_i$ is the frequency of term $j$ in this document.\n",
    "- $\\vec{x} \\cdot \\vec{\\theta}$ is the dot product between vectors $\\vec{x}$ and $\\vec{\\theta}$\n",
    "\n",
    "To classify a document $\\vec{x}$, we can then apply the rule:\n",
    "- If $f(\\vec{x}, \\vec{\\theta}) \\ge 0$\n",
    "  - output $1$\n",
    "- else output $-1$\n",
    "\n",
    "<br><br>\n",
    "Thus,\n",
    "- If $\\theta_j >> 0$ , then term $j$ is associated with the positive class.  \n",
    "- If $\\theta_j << 0$ , then term $j$ is associated with the negative class.\n",
    "<br><br><br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array as npa\n",
    "import numpy as np\n",
    "\n",
    "def f(x, theta):\n",
    "    return np.dot(x.T, theta)\n",
    "\n",
    "x = npa([1,2,3])  # term0 appears 1 time, term1 appears 2 times...\n",
    "theta = npa([-1, -1, 5])  # term 2 predictive of positive class\n",
    "f(x, theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-20"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a negative example.\n",
    "x2 = npa([10, 10, 0])\n",
    "f(x2, theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be understood as a type of regression task. To fit a regression function, we need to pick a model and an error function, then optimize the model parameters somehow. In machine learning, this is most commonly done with the gradient descent algorithm:\n",
    "\n",
    "** Gradient descent recipe **\n",
    "\n",
    "1.  Select a model type (e.g., linear, polynomial, etc)\n",
    "\n",
    "2.  Select an <span>**error function**</span> that, when minimized, results in a good setting of the model parameters.\n",
    "\n",
    "3.  Analytically determine the gradient of the error function with respect to the model parameters.\n",
    "\n",
    "4.  Iteratively change the parameters by a small amount in the direction of the gradient until the (near) minimum of the error function is found.\n",
    "\n",
    "<br><br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RSS\n",
    "\n",
    "Given a labeled dataset $D = \\{(y_1, \\vec{x}_1) \\ldots (y_n, \\vec{x}_n)\\}$ , an intuitive error function is called  \n",
    "*Residual Sum of Squares*\n",
    "\n",
    "$$\n",
    "RSS(\\vec{\\theta}, D) = \\frac{1}{2}\\sum_{i=1}^{|D|}(y_i - f(\\vec{x}_i, \\vec{\\theta}))^2\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rss(theta, D):\n",
    "    error = 0\n",
    "    for xi, yi in D:\n",
    "        prediction = f(xi, theta)\n",
    "        errori = (yi - prediction)**2\n",
    "        error += errori\n",
    "        print('truth=%g  prediction=%g error=%g' %\n",
    "              (yi, prediction, errori))\n",
    "    return error / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "||free|money| |*label*|\n",
    "|:--:|:--------:|:--------:|:--:|:--:|\n",
    "||$x_{i1}$|$x_{i2}$| | $y_i$ |\n",
    "|$x_1$|0|0||-1| \n",
    "|$x_2$|1|0|| 1|\n",
    "|$x_3$|1|1||-1|\n",
    "|$x_4$|1|0||-1|\n",
    "|$x_5$|1|1||1|\n",
    "|$x_6$|0|0||1|\n",
    "|$x_7$|0|1||-1|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "\n",
      "RSS=4\n"
     ]
    }
   ],
   "source": [
    "D = [\n",
    "    (npa([0,0]), -1),\n",
    "    (npa([1,0]), 1),\n",
    "    (npa([1,1]), -1),\n",
    "    (npa([1,1]), -1),\n",
    "    (npa([1,0]), -1),\n",
    "    (npa([1,1]), 1),\n",
    "    (npa([0,0]), 1),\n",
    "    (npa([0,1]), -1),\n",
    "]\n",
    "theta = npa([0,0])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=1 error=0\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=1 error=4\n",
      "truth=1  prediction=2 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=1 error=4\n",
      "\n",
      "RSS=14.5\n"
     ]
    }
   ],
   "source": [
    "theta = npa([1,1])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.5 error=0.25\n",
      "truth=-1  prediction=-0.5 error=0.25\n",
      "truth=-1  prediction=-0.5 error=0.25\n",
      "truth=-1  prediction=0.5 error=2.25\n",
      "truth=1  prediction=-0.5 error=2.25\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-1 error=0\n",
      "\n",
      "RSS=3.625\n"
     ]
    }
   ],
   "source": [
    "theta = npa([0.5,-1])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.5 error=0.25\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0.5 error=2.25\n",
      "truth=1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.5 error=0.25\n",
      "\n",
      "RSS=3.875\n"
     ]
    }
   ],
   "source": [
    "theta = npa([0.5,-0.5])\n",
    "print('\\nRSS=%g' % rss(theta, D))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization problem is then to pick optimal $\\vec{\\theta}^*$ to satisfy:\n",
    "\n",
    "$$ \\vec{\\theta}^* = \\mathrm{argmin}_\\vec{\\theta} \\hspace{.4cm} RSS(\\vec{\\theta}, D)$$\n",
    "\n",
    "<br><br>\n",
    "\n",
    "**Solution:** Gradient descent\n",
    "\n",
    "<img src=\"https://sebastianraschka.com/images/faq/closed-form-vs-gd/ball.png\">\n",
    "\n",
    "while not converged:\n",
    "1. Compute gradient $\\nabla_\\vec{\\theta}$ of $\\vec{\\theta}$ w.r.t. RSS\n",
    "2. Change $\\vec{\\theta}$ in direction of $\\nabla_\\vec{\\theta}$\n",
    "\n",
    "\n",
    "$$\\nabla_\\vec{\\theta} = \\{\\frac{\\partial RSS(f, D)}{\\partial \\theta_1} \\ldots \\frac{\\partial RSS(f, D)}{\\partial \\theta_v}\\}$$\n",
    "\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial RSS(f, D)}{\\partial \\theta_j} &=& \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{2}\\sum_{i=1}^{|D|}(y_i - \\vec{\\theta} \\cdot \\vec{x}_i)^2\\\\\n",
    "&=& \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta} \\cdot \\vec{x}_i)\\frac{\\partial}{\\partial \\theta_j} (y_i - \\theta \\cdot \\vec{x}_i)\\\\\n",
    "&=& \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta} \\cdot \\vec{x}_i)(-x_{ij})\\end{aligned}\n",
    "\n",
    "<br><br>\n",
    "**To update parameters:**\n",
    "\n",
    "$$\\theta_j^{t+1} = \\theta_j^{t} + \\eta \\sum_{i=1}^{|D|}(y_i - \\vec{\\theta}^t \\cdot \\vec{x}_i)x_{ij}$$\n",
    "\n",
    "$\\eta$ = \"learning rate\", to prevent \"jumping over\" minimum\n",
    "\n",
    "<br>\n",
    "\n",
    "What is this update doing?\n",
    "<br><br><br>\n",
    "- Compute error on $i$th example\n",
    "- Adjust parameter $j$ to reduce that error, proportional to how important feature $j$ is for example $i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient(theta, D):\n",
    "    result = np.zeros(len(theta), dtype=np.float64)\n",
    "    for xi, yi in D:\n",
    "        error = yi - f(xi, theta)\n",
    "        for j, xij in enumerate(xi):\n",
    "            result[j] += error * -xij\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.,  2.])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient(npa([0,0]), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=0 error=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss(npa([0, 0]), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=-1 error=4\n",
      "truth=-1  prediction=-3 error=4\n",
      "truth=-1  prediction=-3 error=4\n",
      "truth=-1  prediction=-1 error=0\n",
      "truth=1  prediction=-3 error=16\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-2 error=1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.5"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rss(npa([-1, -2]), D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def gradient_descent(gradient_fn, error_fn, theta,\n",
    "                     learning_rate, D,\n",
    "                     tolerance, max_iters):\n",
    "    errori = error_fn(theta, D)\n",
    "    iters = 0\n",
    "    all_errors = [errori]\n",
    "    while True:\n",
    "        iters += 1\n",
    "        print('\\n\\niteration %d' % iters)\n",
    "        grad = gradient_fn(theta, D)\n",
    "        theta -= learning_rate * grad  # UPDATE!\n",
    "        newerror = error_fn(theta, D)\n",
    "        all_errors.append(newerror)\n",
    "        print('old error=%g   new error=%g  theta=%s\\n\\n' %\n",
    "              (errori, newerror, str(theta)))\n",
    "        error_diff = errori - newerror\n",
    "        if error_diff < 0 or errori - newerror < tolerance \\\n",
    "            or iters >= max_iters:\n",
    "            break\n",
    "        else:\n",
    "            errori = newerror\n",
    "            \n",
    "    plt.plot(all_errors, 'bo-')\n",
    "    plt.xlabel('iteration')\n",
    "    plt.ylabel('error')\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=1 error=0\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=2 error=9\n",
      "truth=-1  prediction=1 error=4\n",
      "truth=1  prediction=2 error=1\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=1 error=4\n",
      "\n",
      "\n",
      "iteration 1\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=-0.8 error=3.24\n",
      "truth=-1  prediction=-1.6 error=0.36\n",
      "truth=-1  prediction=-1.6 error=0.36\n",
      "truth=-1  prediction=-0.8 error=0.04\n",
      "truth=1  prediction=-1.6 error=6.76\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.8 error=0.04\n",
      "old error=14.5   new error=6.4  theta=[-0.8 -0.8]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.28 error=0.5184\n",
      "truth=-1  prediction=0.2 error=1.44\n",
      "truth=-1  prediction=0.2 error=1.44\n",
      "truth=-1  prediction=0.28 error=1.6384\n",
      "truth=1  prediction=0.2 error=0.64\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.08 error=0.8464\n",
      "old error=6.4   new error=4.2616  theta=[ 0.28 -0.08]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 3\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=-0.152 error=1.3271\n",
      "truth=-1  prediction=-0.736 error=0.069696\n",
      "truth=-1  prediction=-0.736 error=0.069696\n",
      "truth=-1  prediction=-0.152 error=0.719104\n",
      "truth=1  prediction=-0.736 error=3.0137\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.584 error=0.173056\n",
      "old error=4.2616   new error=3.68618  theta=[-0.152 -0.584]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 4\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.1504 error=0.72182\n",
      "truth=-1  prediction=-0.2752 error=0.525335\n",
      "truth=-1  prediction=-0.2752 error=0.525335\n",
      "truth=-1  prediction=0.1504 error=1.32342\n",
      "truth=1  prediction=-0.2752 error=1.62614\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.4256 error=0.329935\n",
      "old error=3.68618   new error=3.52599  theta=[ 0.1504 -0.4256]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 5\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.05536 error=0.892345\n",
      "truth=-1  prediction=-0.52 error=0.2304\n",
      "truth=-1  prediction=-0.52 error=0.2304\n",
      "truth=-1  prediction=0.05536 error=1.11378\n",
      "truth=1  prediction=-0.52 error=2.3104\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.57536 error=0.180319\n",
      "old error=3.52599   new error=3.47882  theta=[ 0.05536 -0.57536]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 6\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.145216 error=0.730656\n",
      "truth=-1  prediction=-0.403072 error=0.356323\n",
      "truth=-1  prediction=-0.403072 error=0.356323\n",
      "truth=-1  prediction=0.145216 error=1.31152\n",
      "truth=1  prediction=-0.403072 error=1.96861\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.548288 error=0.204044\n",
      "old error=3.47882   new error=3.46374  theta=[ 0.145216 -0.548288]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 7\n",
      "truth=-1  prediction=0 error=1\n",
      "truth=1  prediction=0.128973 error=0.758688\n",
      "truth=-1  prediction=-0.467814 error=0.283222\n",
      "truth=-1  prediction=-0.467814 error=0.283222\n",
      "truth=-1  prediction=0.128973 error=1.27458\n",
      "truth=1  prediction=-0.467814 error=2.15448\n",
      "truth=1  prediction=0 error=1\n",
      "truth=-1  prediction=-0.596787 error=0.162581\n",
      "old error=3.46374   new error=3.45839  theta=[ 0.1289728 -0.5967872]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.1289728, -0.5967872])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10fced390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = npa([1.,1.])\n",
    "gradient_descent(gradient, rss, theta,\n",
    "                 .2, D, .01, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From regression to classification\n",
    "\n",
    "**Does our error function make sense?**\n",
    "\n",
    "\n",
    "iteration 1  \n",
    "truth=-1  prediction=0 error=1  \n",
    "truth=1  prediction=-0.8 error=3.24  \n",
    "**truth=-1  prediction=-1.6 error=0.36**\n",
    "\n",
    "<br><br>\n",
    "\n",
    "The above assumes that the output variable $y_i$ is a real number. Thus, this is a model of <span>**regression**</span>.  \n",
    "\n",
    "When $y$ is disrete, the problem is one of <span>**classification**</span>.  \n",
    "\n",
    "<br>\n",
    "Recall our three criterion for the function:\n",
    "1. $0 \\le f(y, \\vec{x}) \\le 1$  : values are between 0 and 1\n",
    "2. $\\sum_{y_i} f(y_i, \\vec{x}) = 1$  : values sum to one for all possible classes\n",
    "3. If $f(y_i, \\vec{x}) > f(y_j, \\vec{x})$, then it is more likely that $\\vec{x}$ is of class $i$ than of class $j$\n",
    "\n",
    "<br>\n",
    "We have satisfied 3 (mostly), but not 1 or 2.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "The way around this is to change our model. Rather than regression, we need classification. We can do this by passing the dot product $x_i \\cdot \\theta$ through a “squashing function” (the **logistic function**) that ensures its value is always between 0 and 1: \n",
    "\n",
    "$$f(\\vec{x}_i, \\vec{\\theta}) = \\frac{1}{1 + e^{-\\vec{x}_i \\cdot \\vec{\\theta}}}$$\n",
    "\n",
    "This is called **logistic regression.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf4AAAGACAYAAABMRwCUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl4FOeZ7/3vrQ0BEmBAmFXsXiDGGzbEK96w4xOb7MGJ\nM3HihDixc815MzPnJCcZj9/4zDuT5DpnzszYzoRsnnjNMnGGJM6xsA1ekoDBGwkCbIHZrZZYhQBt\n3ff7R5VwI0uo1ZK6evl9LrfVVfV0cZda3b9+nqquMndHRERECkNR1AWIiIhI5ij4RURECoiCX0RE\npIAo+EVERAqIgl9ERKSAKPhFREQKiIJfRESkgCj4RURECoiCX0REpIAo+EVERApISdQFDIaxY8f6\ntGnToi5DREQkI15++eV97l6VStu8DP5p06axfv36qMsQERHJCDPbkWpbDfWLiIgUEAW/iIhIAVHw\ni4iIFBAFv4iISAFR8IuIiBQQBb+IiEgBUfCLiIgUEAW/iIhIAYk0+M3sR2bWYGZ/7mG5mdm/mFmd\nmW0wswsyXaOIiEg+ibrH/yBwwymWvw+YHd6WAd/NQE0iIiJ5K9Lgd/fngQOnaLIE+IkH1gCjzGxC\nZqoTERHJP9l+rv5JwK6k6d3hvLejKUdERLJNPOG0xxO0xxMkHNydhEPCnYQ7fuI+JBLJ036ifdyd\nRIIu7YPlEMxzwD34N92d8G64LGxAl3ZJj01+XEmRcfnslK6pM+CyPfhTZmbLCHYHUF1dHXE1IiKF\nqaU9zpGWDo60tHOkpYPm1uB+U0vHSfOPtcVpjyfoiCdoj78T3B0Jp63j5PsdYbB3xJ22znbh/Y4w\n7HPNiPISNtxzfST/drYH/x5gStL05HDeu7j7cmA5wPz583Pwz0BEJHu0xxPsPHCMbY1HOXC0lSMt\nHWF4t58U4F3vt8UTva57eFkxw4aUUFZcREmxUVpcREmRUVYS/CwtLmL4kJIT94ObUZJ0vzR8bFlx\nESVFRZSWGKVFRRQVGUUGRRb8NLMT94vMsM5lRZ3TJ7cv6mxfFDzWCOYBmIERrAPATvzvnfnhZPDY\npHaW1Ngs6PFHJduDfwVwl5k9DiwADru7hvlFRAZIU0s72xqPsrWhma2NzdSFP3fsP0ZHN13piiEl\nVJZ33koZU1HGtLHDT8wbUV76zvIhpSfadS6rKC+hOMLQk4iD38weAxYBY81sN/B3QCmAu/8b8CRw\nI1AHHAM+E02lIiK5y915+3ALWxubw4A/eiLgG460nmhXUmRMGzucWeMquH7ueGZWVTCjajhVlUOo\nLC+lYohCOx9EGvzufksvyx24M0PliIjktNaOONv3HUsK+GbqGpvZ1niUY23xE+0qy0uYNa6CK86o\nYmZVBTOrgrCfMnoYpcVRf8tbBlu2D/WLiMgpJBLOC3X7eGTNDp7Z3EA8aXh+0qihzBxXwcXTxjBz\n3PAw5CsYW1GGmXruhUrBLyKSg/Y3t/Lzl3fz6Nqd7DxwjDHDy/jspdM4Z/IoZlYNZ8bYCoaWFUdd\npmQhBb+ISI5wd9bvOMgja3bw5J/qaYsnWDB9NH99/ZncMHc8ZSUappfeKfhFRLLckZZ2nnh1D4+s\n2cmW2BEqy0v4xIJqPrmgmtmnV0ZdnuQYBb+ISJb6857DPLJ2J//52h6OtcU5Z9JIvvXhc7jp3IkM\nK9Pbt6RHfzkiIlmkpT3Obza8zcNrdvDarkOUlxZx87kTuXXhVOZNHhV1eZIHFPwiIllga2Mzj67d\nyS9e3s3h4+3MGlfB3900hw9dMJmRQ0ujLk/yiIJfRCQi7fEEK2tjPLxmB3/Yup/SYuP6ueO5deFU\nFkwfra/cyaBQ8IuIZFhDUwsPrdnB4+t20XiklUmjhvI315/Jx+ZPoapySNTlSZ5T8IuIZNC2xmaW\nLl9DY3MrV585jlsXTuWKM6p0KlzJGAW/iEiGbG1s5pbla4gnnN9++XLmTBwRdUlSgBT8IiIZ0Bn6\nCXceW7aQM/T9e4mIgl9EZJDVNTRzy/fX4O489vmFOumORErndxQRGUTvhD4KfckK6vGLiAySuobg\nQD6Ax5ctYNY4hb5ET8EvIjII6hqOsHT5WkChL9lFwS8iMsDejB3hlu93hv5CZo2riLgikXdoH7+I\nyAAKQn8NZgp9yU4KfhGRAfLGidA3Hvu8Ql+yk4b6RUQGwBuxI3zi+2soMuOxZQuZWaXQl+ykHr+I\nSD+9ETvCLcsV+pIb1OMXEemHLfVBT7+kOBjen6HQlyynHr+ISJoU+pKL1OMXEUnD5vomPvH9tZQW\nG48vey/Txw6PuiSRlKjHLyLSR52hX1ZcpNCXnKMev4hIH2x6u4lP/qAz9BcyTaEvOUY9fhGRFG16\nu4lPfH8NQ0oU+pK71OMXEUlB7d4mPvmDNZSXFvP4soVMHaPQl9ykHr+ISC86Q3+oQl/ygIJfROQU\navc28Ykw9B9T6Ese0FC/iEgPDhxt45M/WMOw0mIeX/ZeqscMi7okkX5Tj19EpAc//v1bHDzWzg9v\nu0ihL3lDwS8i0o2mlnYe/MN2bpg7nrMnjIi6HJEBo+AXEenGQ3/cwZGWDu68albUpYgMKAW/iEgX\nx9vi/OjFt7jyjCrOmTwy6nJEBpSCX0Ski8de2sn+o23cdbV6+5J/FPwiIklaO+J87/mtXDx9NBdN\nGx11OSIDTsEvIpLkP17eQ6yplS+rty95SsEvIhLqiCf4t+e2cu7kkVw2a2zU5YgMCgW/iEjo1xv2\nsvPAMe68ahZmFnU5IoNCwS8iAiQSzgOrtnLm6ZVce/bpUZcjMmgU/CIiQE1tPW82NPOlq2ZSVKTe\nvuQvBb+IFDx3575VdUwbM4z3z5sYdTkig0rBLyIF77k3Gvnznia+uGgmxertS55T8ItIQXN37nu2\njokjy/ng+ZOjLkdk0Cn4RaSgrX3rAOt3HOQLV86krERviZL/9FcuIgXt/lV1jK0YwscvmhJ1KSIZ\noeAXkYL1+q5DvPDmPj53+XTKS4ujLkckIxT8IlKw7ltVx8ihpdy6cGrUpYhkjIJfRArS5vomVtbG\nuO2SaVQMKYm6HJGMUfCLSEF6YNVWhpcV85lLp0VdikhGRR78ZnaDmW0xszoz+2o3y6vNbJWZvWpm\nG8zsxijqFJH88da+o/xmw15ufe9URg0ri7ockYyKNPjNrBi4H3gfMAe4xczmdGn2DeBn7n4+sBR4\nILNViki++e7qOkqLi/jcZTOiLkUk46Lu8V8M1Ln7NndvAx4HlnRp48CI8P5IYG8G6xORPLPn0HF+\n+coell40harKIVGXI5JxUR/RMgnYlTS9G1jQpc09QI2ZfRkYDlybmdJEJB8tf24rAMuunBlxJSLR\niLrHn4pbgAfdfTJwI/CQmb2rbjNbZmbrzWx9Y2NjxosUkezXeKSVx9ft4kMXTGLSqKFRlyMSiaiD\nfw+QfLqsyeG8ZLcDPwNw9z8C5cDYrity9+XuPt/d51dVVQ1SuSKSy37w4jba4wm+uGhW1KWIRCbq\n4F8HzDaz6WZWRnDw3ooubXYC1wCY2dkEwa8uvYj0yaFjbTz8xx38l3kTmT52eNTliEQm0uB39w7g\nLuApYBPB0fsbzeybZnZz2OyvgM+b2evAY8Bt7u7RVCwiuerHv9/O0bY4d16lfftS2KI+uA93fxJ4\nssu8u5Pu1wKXZrouEckfza0dPPiH7Vw353TOGj+i9weI5LGoh/pFRAbdw2t2cPh4O3ddpX37Igp+\nEclrLe1xfvDCW1w+eyznThkVdTkikVPwi0he++m6XexrbuVO9fZFAAW/iOSxto4E33tuK/OnnsaC\n6aOjLkckKyj4RSRv/erVPew93MKdV8/CzKIuRyQrKPhFJC/FE84Dq+t4z6QRLDpDJ/US6aTgF5G8\n9JsNe9m+/xh3XaXevkgyBb+I5J1Ewnlg1VZmj6tg8ZzxUZcjklUU/CKSd57eFGNL7AhfumomRUXq\n7YskU/CLSF5xd+5fVUf16GHcNG9i1OWIZB0Fv4jklRfr9vH67sPcceVMSor1FifSlV4VIpJX7nu2\njvEjyvnwhZOiLkUkKyn4RSRvrNt+gLVvHeDzV8xgSElx1OWIZCUFv4jkjfuerWPM8DJuuXhK1KWI\nZC0Fv4jkhT/vOcxzbzTy2cumM6ws8iuOi2QtBb+I5IWfr99FeWkRn3rv1KhLEclqCn4RyXnuzsra\nGJfPrmJEeWnU5YhkNQW/iOS8jXub2Hu4hcVzTo+6FJGsp+AXkZxXs7GeIoNrzlbwi/RGwS8iOa+m\nNsZF00YzenhZ1KWIZD0Fv4jktJ37j7G5/gjXaZhfJCUKfhHJaTW19QC6Cp9IihT8IpLTampjnDW+\nkuoxw6IuRSQnKPhFJGftb25l/fYDLJ6r3r5IqhT8IpKzntncQMLR1/hE+kDBLyI5q2ZjjEmjhjJ3\n4oioSxHJGQp+EclJx9vivFjXyHVzTsfMoi5HJGco+EUkJz3/ZiMt7QkN84v0kYJfRHJSzcYYI4eW\nctH00VGXIpJTFPwiknM64gme2RzjmrPGUVqstzGRvtArRkRyzrrtBzl0rF1n6xNJg4JfRHLOytoY\nZSVFXHFGVdSliOQcBb+I5BR3p6a2nstnjWX4kJKoyxHJOQp+Eckpm94+wu6Dx1k8V8P8IulQ8ItI\nTqmprccMrj5LwS+SDgW/iOSUmo0xLqw+jarKIVGXIpKTFPwikjN2HzxG7dtNGuYX6QcFv4jkjJW1\nMQCum6Or8YmkS8EvIjmjZmOMM06vYPrY4VGXIpKzFPwikhMOHm3jpe0HdNIekX5S8ItITnh2cwPx\nhLNYw/wi/aLgF5GcsLI2xvgR5ZwzaWTUpYjkNAW/iGS9lvY4z73RyHVzTqeoyKIuRySnKfhFJOu9\n+OY+jrfH9TU+kQGg4BeRrFdTW0/lkBIWTB8TdSkiOU/BLyJZLZ5wntnUwFVnjaOsRG9ZIv2lV5GI\nZLVXdh5k/9E2DfOLDBAFv4hktZqN9ZQVF3HlGVVRlyKSFxT8IpK13J2a2hiXzBpDZXlp1OWI5AUF\nv4hkrTdizezYf0xn6xMZQJEHv5ndYGZbzKzOzL7aQ5uPmVmtmW00s0czXaOIRKNmYz0A152t4BcZ\nKCVR/uNmVgzcD1wH7AbWmdkKd69NajMb+BpwqbsfNLNx0VQrIpm2clOM86tHMW5EedSliOSNPvf4\nzexCM7vbzLr9CG5m48Pl56WwuouBOnff5u5twOPAki5tPg/c7+4HAdy9oa81i0ju2XvoOBt2H9a5\n+UUGWDpD/X8FfA7oKYBjwO3AV1JY1yRgV9L07nBesjOAM8zs92a2xsxu6GO9IpKDnt4UA9D+fZEB\nls5Q/3uBVe7u3S10dzezZ4Er+lXZO0qA2cAiYDLwvJmd4+6HkhuZ2TJgGUB1dfUA/dMiEpWajTFm\nVA1n1riKqEsRySvp9PjHE/TMT2UvMCGFde0BpiRNTw7nJdsNrHD3dnd/C3iD4IPASdx9ubvPd/f5\nVVX6vq9ILjt8vJ012/ZrmF9kEKQT/MeA3pK1CmhNYV3rgNlmNt3MyoClwIoubX5F0NvHzMYSDP1v\n60vBIpJbVm9poCPhOlufyCBIJ/hfA5aYWbfjb2Y2guAAvdd6W5G7dwB3AU8Bm4CfuftGM/ummd0c\nNnsK2G9mtcAq4G/cfX8adYtIjqjZGKOqcgjnTR4VdSkieSedffzLgceAlWb2BXff0LnAzM4FvgeM\nDdv1yt2fBJ7sMu/upPtOcKBgKgcLikiOa2mPs3pLAzefN4miIou6HJG80+fgd/efmtn7gL8AXjWz\nGMF++UnA6YABP3H3xwa0UhEpCH/cup+jbXEN84sMkrTO3OfutwF3ALUEB/tdGP7cCCwLl4uI9FlN\nbT3Dy4q5ZOaYqEsRyUtpn7nP3ZcDy81sGDAKOOTuxwasMhEpOImEs7K2gUVnjWNISXHU5YjkpX6f\nsjcMewW+iPTbq7sOsa+5lcU6aY/IoIn8Ij0iIp1qauspKTIWnalLcogMll57/Ga2DXDgWnd/K5xO\nhbv7zH5VJyIFZeXGGO+dOYaRQ0ujLkUkb6XS4y/q0q6I4Mj93m4aTRCRlNU1NLNt31EN84sMsl57\n/O4+7VTTIiIDoaa2HoBrFfwig0q9chHJCjUbY8ybPJIJI4dGXYpIXutz8JvZs2b2F720uTW8Qp+I\nSK9iTS28tuuQhvlFMiCdHv8iYFovbaYCV6axbhEpQCtrYwAsnqur8YkMtsEa6h8KdAzSukUkz6ys\njTFtzDBmj+v22l8iMoDSDX7vbqYFpgI3ArvSrkpECsaRlnb+sHUfi+eOx0wX5REZbCkFv5klzCxu\nZvFw1j2d08k3gl7+NuA84PFBqllE8sjqLY20x53rtH9fJCNSPWXv87zTy78C2Als76ZdHNgPPAP8\noL/FiUj+q6mNMWZ4GRdUnxZ1KSIFIaXgd/dFnffNLAH82N2/OVhFiUhhaOtIsHpzAzeeM4HiIg3z\ni2RCOhfpmQ4cGuhCRKTwrNm2nyOtHSyeq2F+kUzpc/C7+47u5pvZGILdAMeAp9093l07EZFONbX1\nDCsr5tJZY6MuRaRgpHMCny+a2VozG50070JgM/AL4EngD2Y2fODKFJF8k0g4K2tjXDG7ivLS4qjL\nESkY6Xyd7+MEV947kDTvO8BpwI8Jgv8i4I7+lyci+WrDnsPEmlo1zC+SYekE/2xgQ+eEmY0lOEvf\nD939c+5+E7AO+MTAlCgi+ahmYz3FRcbVZ42LuhSRgpJO8I8BGpKmLw1/PpE07wWC0/aKiHRrZW2M\nBdNHM2pYWdSliBSUdIL/AJB8JM6VQAL4Q9I8B8r7UZeI5LFtjc282dCsi/KIRCCd4N8E3GRmY8xs\nFLAUWOfuTUltpgH1A1CfiOShzovyXKvgF8m4dIL/n4EJwG6C8/GfDjzQpc1C4PX+lSYi+aqmNsac\nCSOYfNqwqEsRKTh9Dn53X0FwxP5GYAvw1+7+cOdyM1sEVABPDVCNIpJHGo+08srOg1yvS/CKRCKd\nM/fh7suB5T0sW03w1T4RkXd5ZlMMd/Q1PpGIpHtZXhGRtNTUxpgyeihnja+MuhSRgtRrj9/MqsO7\ne9w9njTdK3ffmXZlIpJ3mls7eLFuH7cumIqZLsojEoVUhvq3E3w972zgjaTp3niK6xeRAvH8G420\ndSQ0zC8SoVSC+ScEIX64y7SISJ/UbKzntGGlzJ+qw4BEotJr8Lv7baeaFhFJRXs8wbObG1g8dzwl\nxTq8SCQqevWJSEa89NYBmlo6uE4n7RGJlIJfRDKiZmM95aVFXDG7KupSRApanw++M7MfpdAsATQR\nnN731+6u0/eKFDB3p6Y2xuWzqxhaVhx1OSIFLZ2j7m/jnYP7uvs+jneZf5+ZfcPdv5PGvyUieeDP\ne5p4+3ALX7nujKhLESl46Qz1zwT+E9gPfANYRPBVv0XA34bznwAWAF8AYsA/mtmS/pcrIrloZW09\nRQbXnK39+yJRS6fH/wHgcuA8d9+TNH8L8LyZ/QR4FXjB3f+PmT0F1AJ3EXxgEJECU1MbY/600Ywe\nXhZ1KSIFL50e/zLg511C/wR33wX8PGzXefa+3wAXpFukiOSuHfuPsrn+CIt1NL9IVkgn+Kfxzsl8\nenIImJ40vZ3gin0iUmBW1sYAWDxHV+MTyQbpBP8+4Lpe2iwm2NffaRS9f1gQkTxUszHGWeMrqR4z\nLOpSRIT0gv8/gAvM7OGuF+wxs2ozewQ4D/hF0qILgTfTL1NEctH+5lbW7zjA4rnq7Ytki3QO7rub\n4OC+TwAfN7M9BEfunw5MAoqB18J2mNkEoB14aCAKFpHc8czmBhKO9u+LZJE+B7+7N5nZJcB/Az4N\nzAA6e/7bCC7i8213bwnbvw1cMjDlikguqdkYY+LIcuZOHBF1KSISSuuyue7eCtwL3GtmlcAIoMnd\njwxkcSKSu461dfDCm43ccnE1Zt2d60tEopBW8CcLw16BLyInef6NfbR2JDTML5Jl0g5+MxsGfAg4\nn3eO2n8FeMLdjw5MeSKSq1bWxhg5tJSLpo+OuhQRSZJW8JvZjcC/A6M5+bz8DvyTmX3G3X8zAPWJ\nSA7qiCd4ZnOMq88aR2mxLgIqkk3SuTrfBcAvCY7efwR4FngbmABcDdwC/MLMLnX3lwewVhHJEeu2\nH+TQsXYN84tkoXR6/F8n6Nlf7u5ruix70MzuB1YD/wP4cP/KE5FcVFNbT1lJEVecURV1KSLSRTpj\ncJcTnKu/a+gD4O5rCU7ec3kqKzOzG8xsi5nVmdlXT9Huw2bmZjY/jZpFJEPcnZqNMS6fNZbhQ/p9\n/LCIDLB0gn8ksKuXNjsJvuJ3SmZWDNwPvA+YA9xiZnO6aVcJ/CWwts/VikhGbXr7CHsOHWfxXA3z\ni2SjdIJ/L3BxL23mE+z3783FQJ27b3P3NuBxYEk37e4FvgW09KVQEcm8mtp6zODqsxT8ItkoneB/\nErjazL4a9thPMLMiM/sr4NqwXW8mcfLowe5wXvI6LwCmuPtv06hVRDKsZmOMC6tPo6pySNSliEg3\n0tkBdy/wAeDvgS+Y2QsEvfvxwGUEl+2tB/5nf4szsyLgfwO3pdB2GbAMoLq6upfWIjIYdh04Ru3b\nTfyPG8+KuhQR6UE65+qvN7NLge8RXJ53apcmK4E7wnP092YPMCVpenI4r1Ml8B5gdXjKz/HACjO7\n2d3Xd6lrObAcYP78+Z76FonIQFlZGwPgujm6Gp9Itkr3XP3bgevNbBLBmftGEpy571V333Oqx3ax\nDphtZtMJAn8pwVX/Ov+dw8DYzmkzWw38ddfQF5HssLI2xhmnVzB97PCoSxGRHvTruzZhyPcl6Ls+\nvsPM7gKeIjgh0I/cfaOZfRNY7+4r+lOfiGTOwaNtvLT9AHdcOSPqUkTkFHoNfjP7UZrrdne/PYVG\nT9LlQEB3v7uHtovSrEVEBtmzmxuIJ5zFGuYXyWqp9PhvS3PdDvQa/CKSH2pq6xk/opxzJo2MuhQR\nOYVUgn/6oFchIjmtpT3O82/s4yMXTqaoyHp/gIhEptfgd/cdmShERHLXi2/u43h7XGfrE8kBul6m\niPRbTW09lUNKWDB9TNSliEgvFPwi0i/xhPP0pgauOmscZSV6SxHJdnqViki/vLzjIAeOtmmYXyRH\nKPhFpF9qNtZTVlzElWdURV2KiKRAwS8iaXN3Vm6KccmsMVSWl0ZdjoikQMEvIml7I9bMjv3HuG6O\nhvlFcoWCX0TSVrOxHoDrzlbwi+QKBb+IpK2mNsb51aMYN6I86lJEJEUKfhFJy95Dx/nTnsM6N79I\njlHwi0hant4UA9DX+ERyjIJfRNJSszHGjKrhzKyqiLoUEekDBb+I9NnhY+2s2bZfw/wiOUjBLyJ9\ntmpLAx0J1zC/SA5S8ItIn9XU1lNVOYTzJo+KuhQR6SMFv4j0SUt7nOe2NHLdnNMpKrKoyxGRPlLw\ni0if/HHrfo62xXW2PpEcpeAXkT6pqa1neFkxl8wcE3UpIpIGBb+IpCyecFbWxlh01jiGlBRHXY6I\npEHBLyIpe23XQfY1t7FYw/wiOUvBLyIpq6mNUVpsXHXWuKhLEZE0KfhFJCXuTs3GGAtnjGFEeWnU\n5YhImhT8IpKSrY3NvLXvqIb5RXKcgl9EUvLUxuCiPNcq+EVymoJfRFJSUxvj3MkjmTByaNSliEg/\nKPhFpFexphZe33WIxXN1UR6RXKfgF5FerawNhvl1tj6R3KfgF5Fe1dTGmDZmGLPHVURdioj0k4Jf\nRE6pqaWdP27dx+K54zHTRXlEcp2CX0ROafWWRtrjrq/xieQJBb+InNLK2hhjK8o4v/q0qEsRkQGg\n4BeRHrV1JFi9uYFrzjqd4iIN84vkAwW/iPRoxet7OdLawY3zJkRdiogMEAW/iHQrnnAeWF3H2RNG\ncMXssVGXIyIDRMEvIt36v3+uZ1vjUe66apaO5hfJIwp+EXkXd+e+VXXMqBrODe/R2fpE8omCX0Te\nZdWWBja93cSXFs3SQX0ieUbBLyIncXf+9dk6Jp82lCXnTYy6HBEZYAp+ETnJH7fu59Wdh/jClTMp\nLdZbhEi+0ataRE5y36o6xlUO4aMXTo66FBEZBAp+ETnhlZ0H+cPW/Xz+8hmUlxZHXY6IDAIFv4ic\ncP+zdYwaVsonFlRHXYqIDBIFv4gAULu3iWc2N/DZS6czfEhJ1OWIyCBR8IsIAPevrqNySAmfvmRa\n1KWIyCBS8IsIWxubefJPb/Op905l5NDSqMsRkUGk4BcRvrt6K0NKirj9sulRlyIig0zBL1Lgdh04\nxhOv7uGWi6sZUzEk6nJEZJAp+EUK3Pee30qRwbIrZkRdiohkgIJfpIA1NLXws/W7+ciFk5kwcmjU\n5YhIBkQe/GZ2g5ltMbM6M/tqN8u/Yma1ZrbBzJ4xs6lR1CmSj77/wjY64gnuuHJm1KWISIZEGvxm\nVgzcD7wPmAPcYmZzujR7FZjv7vOAXwDfzmyVIvnp4NE2Hlm7k5vPncjUMcOjLkdEMiTqHv/FQJ27\nb3P3NuBxYElyA3df5e7Hwsk1gE4gLjIAfvz7tzjWFudLV82KuhQRyaCog38SsCtpenc4rye3A78b\n1IpECsCRlnYe/MN2bpg7njNOr4y6HBHJoJw5L6eZ3QrMB67sYfkyYBlAdbXOMy5yKg+t2UFTSwd3\nqrcvUnCi7vHvAaYkTU8O553EzK4Fvg7c7O6t3a3I3Ze7+3x3n19VVTUoxYrkg+NtcX74wltceUYV\n50weGXU5IpJhUQf/OmC2mU03szJgKbAiuYGZnQ98jyD0GyKoUSSvPPbSTvYfbeOuq9XbFylEkQa/\nu3cAdwFPAZuAn7n7RjP7ppndHDb7DlAB/NzMXjOzFT2sTkR60doRZ/nz27h4+mgumjY66nJEJAKR\n7+N39yeBJ7vMuzvp/rUZL0okT/3ylT3UN7Xw7Y/Mi7oUEYlI1EP9IpIhHfEE3129lXmTR3L57LFR\nlyMiEVHwixSI32x4m50HjnHnVbMws6jLEZGIKPhFCkAi4dy/qo4zTq/gurNPj7ocEYmQgl+kANTU\n1vNmQzNvmC9QAAAR90lEQVR3XjWLoiL19kUKmYJfJM+5O/etqmPamGG8f97EqMsRkYgp+EXy3HNv\nNPLnPU18cdFMitXbFyl4Cn6RPHf/qjomjizng+fr+lYiouAXyWtrt+1n3faDLLtiBmUlermLiIJf\nJK/dt6qOsRVlLL1YF64SkYCCXyRPvb7rEC+8uY/bL5tBeWlx1OWISJZQ8IvkqftX1TGivIRbF6q3\nLyLvUPCL5KHN9U3U1Mb4zKXTqSwvjbocEckiCn6RPPTAqq0MLyvmM5dOi7oUEckyCn6RPLN931F+\ns2Evty6cyqhhZVGXIyJZRsEvkme+u3orJcVF3H759KhLEZEspOAXySN7Dx3nl6/uZulFUxhXWR51\nOSKShRT8Inlk+fPbcIcvXDkz6lJEJEsp+EXyROORVh57aScfPH8Sk0YNjbocEclSCn6RPNAeT/D1\nJ/5EWzzBFxepty8iPVPwi+S49niCLz/6KjW1Mf72v8xhRlVF1CWJSBYriboAEUlfW0eCLz/2Ck9t\njHH3++fw2ct0JL+InJqCXyRHtXUkuOvRV6ipjfF3N83hM5cq9EWkdwp+kRzU1pHgzkdfYWVtjHtu\nmsNtCn0RSZGCXyTHJIf+/3vzXD59ybSoSxKRHKLgF8khbR0JvvTIKzy9KcY3l8zlL947LeqSRCTH\nKPhFckRrR5w7H3mFpzc1cO+SuXxKoS8iadDX+URygEJfRAaKevwiWa61I86XHn6FZzY3cO8H3sOn\nFk6NuiQRyWEKfpEs1toR54sPv8Kzmxv4nx94D7cq9EWknxT8IlkqOfT//oPv4ZMLFPoi0n8KfpEs\n1NIe54sPv8yqLY38fx88h08sqI66JBHJEwp+kSzT0h7njodfZrVCX0QGgYJfJIu0tMf5wkMv89wb\njfzDh87hlosV+iIysBT8IlkiOfT/8UPnsFShLyKDQMEvkgVa2uMse+hlXnizkW99+Bw+fpFCX0QG\nh4JfJGIt7XE+/5P1vFi3j299aB4fu2hK1CWJSB7TmftEIqTQF5FMU49fJCInhf6H5/Gx+Qp9ERl8\nCn6RCCSH/rc/PI+PKvRFJEMU/CIZ1B5PsLI2xvee28qGPYf5zkfO5SMXTo66LBEpIAp+kQzYe+g4\nj720k8fX7aLxSCuTRg3lX5aez03nToy6NBEpMAp+kUESTzjPv9nII2t28OzmBhy46sxxfHJBNYvO\nHEdxkUVdoogUIAW/yADb19zKz9bv4tG1O9l98DhjK8r44qKZLL2omimjh0VdnogUOAW/yABwd156\n6wCPrN3J7/78Nu1xZ+GM0fz3G87i+rnjKSvRN2dFJDso+EX6oamlnSde2cMja3fwRqyZyvISPrlg\nKrcurGbWuMqoyxMReRcFv0ga/rT7MI+s3cF/vraX4+1x5k0eybc/PI+bzp3I0LLiqMsTEemRgl8k\nRcfb4vx6w14eWbOD13cfpry0iCXnTuKTC6uZN3lU1OWJiKREwS9yCu5OXUMzj760k/94eTdNLR3M\nGlfBPTfN4YMXTGbk0NKoSxQR6RMFvwjQ1pFgx/6jbG1sZmvjUeoamoP7Dc0cbYtTWmzc8J4J3Lqg\nmounj8ZMX8UTkdyk4JeCcvhYO3WNYaiHwb618Sg7DxwjnvAT7SaOLGfmuAo+On8Ks8ZVcP3c8VRV\nDomwchGRgRF58JvZDcA/A8XAD9z9H7ssHwL8BLgQ2A983N23Z7pOyR2JhLPn0PETvfetjc3UNTSz\nrbGZfc1tJ9qVFRcxfexwzp5QyfvnTWBmVQUzqyqYUTWc4UMif2mIiAyKSN/dzKwYuB+4DtgNrDOz\nFe5em9TsduCgu88ys6XAt4CPZ75aybSOeILm1g6OtHTQ1NLOkZaO8Nbe4/xYUytv7WumpT1xYj2j\nhpUyq6qCa846nZnjhjNrXBDwk08bprPniUjBibpbczFQ5+7bAMzscWAJkBz8S4B7wvu/AO4zM3N3\nRwaFu5NwSLgHtwS0JxJ0xJ32eCK8nXy/I56gLd59m464h8uCeZ3tjrYFYd2UFNzJP4+1xXuttayk\niBHlJVSWl1JZXsKEkeVcNmtM0HsPA3708LIM/NZERHJD1ME/CdiVNL0bWNBTG3fvMLPDwBhgXyYK\nfLo2xv2r605MJ3/ceNcnjy6fRbouP/mxfmLaPWib/FkmmJfUJlzuSStOnvdOuyCoTw7vzul35rkH\n55LvvJ9IWp4pQ0qKqCwvDYM7CO/xI8pP3E/+OaKbeZXlJQwp0XfmRUT6IurgHzBmtgxYBlBdXT1g\n6y0pNiq67O9NPqK760Bx14O937385Me+M2mYvdM+uB/OsxMtCP87sR470fadeUVmFFn4syiYf2La\ngnUmtzEzioveuV+UtNzCx5QWG6XFRZSEP0tP/HznfklREWUlRknRyfNLS4ooLer6+CINs4uIRCDq\n4N8DTEmanhzO667NbjMrAUYSHOR3EndfDiwHmD9//oD1WxedOY5FZ44bqNWJiIhEKuorh6wDZpvZ\ndDMrA5YCK7q0WQF8Orz/EeBZ7d8XERFJT6Q9/nCf/V3AUwRf5/uRu280s28C6919BfBD4CEzqwMO\nEHw4EBERkTREPdSPuz8JPNll3t1J91uAj2a6LhERkXwU9VC/iIiIZJCCX0REpIAo+EVERAqIgl9E\nRKSAKPhFREQKiIJfRESkgCj4RURECoiCX0REpIAo+EVERAqIgl9ERKSAWD5e78bMGoEdA7jKscC+\nAVxftsjH7crHbYL83C5tU+7Ix+3Kt22a6u5VqTTMy+AfaGa23t3nR13HQMvH7crHbYL83C5tU+7I\nx+3Kx21KlYb6RURECoiCX0REpIAo+FOzPOoCBkk+blc+bhPk53Zpm3JHPm5XPm5TSrSPX0REpICo\nxy8iIlJAFPwhM/uomW00s4SZze+y7GtmVmdmW8zs+h4eP93M1obtfmpmZZmpPHVhXa+Ft+1m9loP\n7bab2Z/CduszXWdfmNk9ZrYnabtu7KHdDeHzV2dmX810nX1hZt8xs81mtsHMnjCzUT20y4nnqbff\nvZkNCf8268LX0LTMV5k6M5tiZqvMrDZ8z/jLbtosMrPDSX+Xd0dRa1/19jdlgX8Jn6sNZnZBFHWm\nyszOTHoOXjOzJjP7r13a5ORz1S/urluwu+Ns4ExgNTA/af4c4HVgCDAd2AoUd/P4nwFLw/v/Bnwx\n6m3qZXv/F3B3D8u2A2OjrjHF7bgH+Ote2hSHz9sMoCx8PudEXfsp6l0MlIT3vwV8K1efp1R+98CX\ngH8L7y8Ffhp13b1s0wTggvB+JfBGN9u0CPhN1LWmsW2n/JsCbgR+BxiwEFgbdc192LZioJ7g++45\n/1z156Yef8jdN7n7lm4WLQEed/dWd38LqAMuTm5gZgZcDfwinPXvwAcGs97+COv9GPBY1LVkyMVA\nnbtvc/c24HGC5zUruXuNu3eEk2uAyVHW00+p/O6XELxmIHgNXRP+jWYld3/b3V8J7x8BNgGToq0q\nY5YAP/HAGmCUmU2IuqgUXQNsdfeBPLlbTlLw924SsCtpejfvfpGPAQ4lvVl31yabXA7E3P3NHpY7\nUGNmL5vZsgzWla67wmHHH5nZad0sT+U5zFafJehhdScXnqdUfvcn2oSvocMEr6msF+6WOB9Y283i\n95rZ62b2OzObm9HC0tfb31Quv5aW0nNnJxefq7SVRF1AJpnZ08D4bhZ93d3/M9P1DIYUt/EWTt3b\nv8zd95jZOGClmW129+cHutZUnWqbgO8C9xK8Yd1LsAvjs5mrLj2pPE9m9nWgA3ikh9Vk1fNUaMys\nAvgP4L+6e1OXxa8QDCk3h8ed/AqYneka05CXf1PhMVc3A1/rZnGuPldpK6jgd/dr03jYHmBK0vTk\ncF6y/QRDXiVhj6W7NhnR2zaaWQnwIeDCU6xjT/izwcyeIBiujezFn+rzZmbfB37TzaJUnsOMSuF5\nug14P3CNhzsiu1lHVj1PPUjld9/ZZnf49zmS4DWVtcyslCD0H3H3X3ZdnvxBwN2fNLMHzGysu2f1\nueFT+JvKutdSit4HvOLusa4LcvW56g8N9fduBbA0PPJ4OsEnwZeSG4RvzKuAj4SzPg1k6wjCtcBm\nd9/d3UIzG25mlZ33CQ40+3MG6+uTLvsXP0j3ta4DZlvwzYsygiG/FZmoLx1mdgPw34Cb3f1YD21y\n5XlK5Xe/guA1A8Fr6NmePuxkg/D4gx8Cm9z9f/fQZnzncQpmdjHBe222f5hJ5W9qBfAX4dH9C4HD\n7v52hktNR4+jnLn4XPVb1EcXZsuNIDR2A61ADHgqadnXCY5M3gK8L2n+k8DE8P4Mgg8EdcDPgSFR\nb1MP2/kgcEeXeROBJ5O24/XwtpFg6Dnyuk+xPQ8BfwI2ELwpTei6TeH0jQRHX2/NgW2qI9iP+lp4\n6zziPSefp+5+98A3CT7YAJSHr5m68DU0I+qae9meywh2LW1Ieo5uBO7ofG0Bd4XPy+sEB2heEnXd\nKWxXt39TXbbLgPvD5/JPJH0DKltvwHCCIB+ZNC+nn6v+3nTmPhERkQKioX4REZECouAXEREpIAp+\nERGRAqLgFxERKSAKfhERkQKi4BfJceHVxdzM7om6FhHJfgp+kSxnZtPCYH+w0GoILxO7KJP/pki+\nU/CLSNYwszHhWeN6Wj41k/WI5CMFv4hkk2XAZjP7ePJMM5ttZr8Dfmdmet8S6Qe9gESyWLjf/q1w\n8tPhcHvn7bZu2p9nZr81s0NmdszMnjOzS3pYd4mZfcnM1phZU9j+VTO7KzlcU6nBzMrCxz1pZjvM\nrNXMDpjZ02b2vlS3193/Afgc8N/N7FmgEvgK8CLwAsEpYhO9/M7+OaztXefRN7Pbw2Ur9QFCCpVO\n2SuSxcL92x8A/pLgXOK/Slr8K3d/LWyzCvgtcDXwR+BVoBr4MNAGnOfuW5LWWwr8Grie4BoUq4EW\n4CpgHvCwu3+qDzWMJ7hK2x/C9TUCE4CbgNHA5939B33Y7mLgp2H9DQSXi30zxceWhb+D84Gb3P23\n4fy5BNcCaAp/H++6UptIQYj6YgG66abbqW/ANIKLwjzYw/JF4XIHbuuy7Avh/Ae6zL8nnP+vQHHS\n/GKCK885sKQPNQwBJnczfyTBFd4OAENT3N7FBNdIX0VwcZVfE1w462vAsBTXMYsg4BuBScCwsI44\nwaWOI39eddMtqpuGukTyx+/d/cEu834EdBBcVx2AcIj7y0A98P+4e7xzWXj/rwhC/pOp/sPu3urd\nXOrZ3Q+HNZwGXNTbeszsa2H7b7v7VcAR4H8RXBHvCmBdKkP07l5HcLzAWOBR4D5gLvAP7v5Mqtsl\nko9Koi5ARAbM+q4z3L3dzGIEwdvpDILh9zeBb4SXIu/qOHB2X/7xcCj9bwgCegLB5XaTTUphNcuB\nf3X35uSZHgzzv8/Mpnov+/iTHvO4mV1DcMzAFQTHCfxdKo8VyWcKfpH8caiH+R0EQ/idxoQ/Z3Pq\nIKxI9R82s4XAswTvKc8AKwiG2hPAecASgt0Bp+Tu+3tZviPVmkK/IAh+CD5QxE/VWKQQKPhFCs/h\n8OcT7v6hAVrnN4ChwFXuvjp5QTh8vySdlbr7tHQLMrOxBMcrHAtn/ZOZrXL3xnTXKZIPtI9fJPt1\n9lKLT9kqdZsJRgcWhkf3D0QNs4ADXUM/dGXfyus/C/Zf/DvB7oW/DG8TgZ9YD/s2RAqFgl8k+x0k\nONiueiBW5u4dBEfzTwD+xcyGdm1jZhPMbE4fatgOjDazeV3WczvBVwYz7SvAjcBP3f0HHnyV8KfA\nDQTHIYgULA31i2Q5d282s7XA5Wb2CPAGQQ98hbtvSHO19wLnAncAN4Uny9kDjCPY938p8HWgNsUa\n/g9BwL9oZj8j2J0wn+Bo/F8AH0mzzj4zs4uAfyA46dAXkhYtI/hmwd+b2fPuviZTNYlkEwW/SG74\nFPBPBD3WWwADdgNpBX94tP8HgFuB24D3ExzM10gQmH8LPJJqDe7+f83sJoJ9/R8n+FDwEsEJgWaQ\noeA3s5EEPXuApeHXCQFw96bwVMC/Bx4zs/PdvacDIkXyls7cJyIiUkC0j19ERKSAKPhFREQKiIJf\nRESkgCj4RURECoiCX0REpIAo+EVERAqIgl9ERKSAKPhFREQKiIJfRESkgCj4RURECsj/D56Ilyxa\nwFRRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110b984e0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from math import exp\n",
    "def logistic(x, theta):\n",
    "    return 1 / (1 + exp(-f(x, theta)))\n",
    "    \n",
    "x = npa([1])\n",
    "\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(range(-10, 10), [logistic(x, theta) for theta in range(-10, 10)])\n",
    "plt.xlabel('theta * x', size=20)\n",
    "plt.ylabel('logistic', size=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because $f(x_i, \\vec{\\theta})$ will always be between 0 and 1, and will sum to one for both classes, we have the right to call this a <span>**probability**</span> $p(y_i=1|\\vec{x}_i)$.  \n",
    "\n",
    "$$f(\\vec{x}_i) = p(y_i=1|\\vec{x}_i) = \\frac{1}{1 + e^{-\\vec{x}_i \\cdot \\vec{\\theta}}}$$\n",
    "\n",
    "and, for binary classification, the probability of a negative example:\n",
    "\n",
    "$$\n",
    "p(y_i=-1|\\vec{x}_i) = 1 - p(y_i=1|\\vec{x}_i)\n",
    "$$\n",
    "\n",
    "with some algebra, it turns out that:\n",
    "\n",
    "$$\n",
    "p(y_i=-1|\\vec{x}_i) = \\frac{1}{1 + e^{\\vec{x}_i \\cdot \\vec{\\theta}}}\n",
    "$$\n",
    "\n",
    "Because of this, if $y_i \\in \\{-1, 1\\}$, we can write:\n",
    "\n",
    "$$\n",
    "p(y_i|\\vec{x}_i) =  \\frac{1}{1 + e^{-y_i \\vec{x}_i \\cdot \\vec{\\theta}}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What is a good error function for logistic regression?**\n",
    "\n",
    "We can now rephrase our learning objective as maximizing the <span>*joint probability of the true labels for all training instances.*</span>  \n",
    "\n",
    "Since we assume each instance is drawn independently, we can write this joint probability as a product of individual probabilities: \n",
    "\n",
    "$$p(y_1 \\ldots y_n|\\vec{x}_1 \\ldots \\vec{x}_n) = p(y_1|\\vec{x}_n) * p(y_2|\\vec{x}_2) * \\ldots * p(y_n|\\vec{x}_n) = \\prod_{i=1}^{n}p(y_i|\\vec{x}_i)$$\n",
    "\n",
    "Because we’re used to minimizing functions using gradient descent, rather than maximizing the probability, we can instead minimize the negative probability. This is our new error function: \n",
    "\n",
    "$$\n",
    "E(D, h) = - \\prod_{i=1}^{n}p(y_i|x_i)\n",
    "$$\n",
    "\n",
    "Note that this is very similar to RSS, but by using probabilities, we ensure that the output for each instance is always between 0 and 1.\n",
    "\n",
    "<br><br>\n",
    "\n",
    "Following our learning recipe, our next step is to minimize $E(D,h)$ using gradient descent.  \n",
    "\n",
    "Computing the gradient of $E(D,h)$ in its current form is rather hard. So, we can simply transform it to something that’s easier to take the gradient of: \n",
    "\n",
    "$$E(D,h) = - \\ln \\prod_{i=1}^n  p(y_i|\\vec{x}_i) = -\\sum_i \\ln p(y_i|\\vec{x}_i)$$\n",
    "\n",
    "This is called the <span>**negative log likelihood**</span>. It turns out that minimizing $f(x)$ or $\\ln f(x)$ results in the same answer, so we can make this transformation without affecting our final solution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import log\n",
    "\n",
    "def nll(theta, D):\n",
    "    total = 0\n",
    "    for xi, yi in D:\n",
    "        pred = logistic(xi, theta) if yi==1 else 1-logistic(xi, theta)\n",
    "        print('truth=%g  pr(true label)=%g' % \n",
    "              (yi, pred))\n",
    "        total += log(pred)\n",
    "    return -total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we’re ready to calculate the gradient with respect to one parameter $\\theta_j$:\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial E(D,f)}{\\partial \\theta_j} & = & \\frac{\\partial}{\\partial \\theta_j}- \\ln \\prod_i \\frac{1}{1 + e^{-y_i x_i \\cdot \\theta}} \\\\\n",
    "& = &  \\frac{\\partial}{\\partial \\theta_j}-  \\sum_i \\ln \\frac{1}{1 + e^{-y_i x_i \\cdot \\theta}} \\quad \\hbox{(by definition of log of products)}\\\\\n",
    "& = &  -  \\sum_i 1 + e^{-y_i x_i \\cdot \\theta} \\frac{\\partial}{\\partial \\theta_j} \\frac{1}{1 + e^{-y_i x_i \\cdot \\theta}} \\quad  \\hbox{  (by }\\frac{d}{dx}\\ln(f(x)) = \\frac{1}{f(x)} \\frac{d}{dx}f(x) ) \\\\\n",
    "& = &  -  \\sum_i (1 + e^{-y_i x_i \\cdot \\theta})\\Big(\\frac{-y_ix_{ij} e^{-y_ix_i \\cdot \\theta}}{(1 + e^{-y_ix_i\\cdot \\theta})^2}\\Big) \\quad \\hbox{    (by quotient and chain rules) }\\\\\n",
    "& = & - \\sum_i \\frac{-y_i x_{ij} e^{-y_i x_i \\cdot \\theta}}{1 + e^{-y_i x_i \\cdot \\theta}} \\quad \\hbox{     (by algebra) }\\\\\n",
    "& = & \\sum_i y_i x_{ij} (1 - p(y_i | x_i)) \\quad \\Big( \\hbox{by }\\frac{e^{-y_i x_i \\cdot \\theta}}{1 + e^{-y_i x_i \\cdot \\theta}} = 1 - p(y_i|x_i) \\Big)\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "Thus, the final logistic regression update is: \n",
    "\n",
    "$$\n",
    "\\theta_j^{t+1} \\leftarrow \\theta_j^{t} + \\eta \\sum_i y_i x_{ij}(1-p(y_i|\\vec{x}_i))\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_logistic(theta, D):\n",
    "    result = np.zeros(len(theta), dtype=np.float64)\n",
    "    for xi, yi in D:\n",
    "        pred = logistic(xi, theta) if yi==1 else 1-logistic(xi, theta)\n",
    "        error = yi * (1-pred)\n",
    "        for j, xij in enumerate(xi):\n",
    "            result[j] -= error * xij\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.731059\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.268941\n",
      "truth=1  pr(true label)=0.880797\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.268941\n",
      "\n",
      "\n",
      "iteration 1\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.687735\n",
      "truth=-1  pr(true label)=0.174768\n",
      "truth=-1  pr(true label)=0.174768\n",
      "truth=-1  pr(true label)=0.312265\n",
      "truth=1  pr(true label)=0.825232\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.31807\n",
      "old error=8.70686   new error=7.75071  theta=[ 0.78954916  0.76265502]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.64667\n",
      "truth=-1  pr(true label)=0.240247\n",
      "truth=-1  pr(true label)=0.240247\n",
      "truth=-1  pr(true label)=0.35333\n",
      "truth=1  pr(true label)=0.759753\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.366586\n",
      "old error=7.75071   new error=6.99303  theta=[ 0.6044327   0.54689247]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 3\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.609967\n",
      "truth=-1  pr(true label)=0.309427\n",
      "truth=-1  pr(true label)=0.309427\n",
      "truth=-1  pr(true label)=0.390033\n",
      "truth=1  pr(true label)=0.690573\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.412019\n",
      "old error=6.99303   new error=6.42515  theta=[ 0.44717288  0.35562518]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 4\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.578839\n",
      "truth=-1  pr(true label)=0.375742\n",
      "truth=-1  pr(true label)=0.375742\n",
      "truth=-1  pr(true label)=0.421161\n",
      "truth=1  pr(true label)=0.624258\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.452728\n",
      "old error=6.42515   new error=6.01913  theta=[ 0.3180077   0.18965527]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 5\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.553535\n",
      "truth=-1  pr(true label)=0.434721\n",
      "truth=-1  pr(true label)=0.434721\n",
      "truth=-1  pr(true label)=0.446465\n",
      "truth=1  pr(true label)=0.565279\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.48809\n",
      "old error=6.01913   new error=5.73791  theta=[ 0.21496244  0.04765051]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 6\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.533617\n",
      "truth=-1  pr(true label)=0.484618\n",
      "truth=-1  pr(true label)=0.484618\n",
      "truth=-1  pr(true label)=0.466383\n",
      "truth=1  pr(true label)=0.515382\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.518273\n",
      "old error=5.73791   new error=5.54601  theta=[ 0.13467196 -0.07312408]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 7\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.518325\n",
      "truth=-1  pr(true label)=0.525622\n",
      "truth=-1  pr(true label)=0.525622\n",
      "truth=-1  pr(true label)=0.481675\n",
      "truth=1  pr(true label)=0.474378\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.543865\n",
      "old error=5.54601   new error=5.41508  theta=[ 0.07333389 -0.17591143]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 8\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.506838\n",
      "truth=-1  pr(true label)=0.558847\n",
      "truth=-1  pr(true label)=0.558847\n",
      "truth=-1  pr(true label)=0.493162\n",
      "truth=1  pr(true label)=0.441153\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.56558\n",
      "old error=5.41508   new error=5.3248  theta=[ 0.02735541 -0.26383837]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 9\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.49841\n",
      "truth=-1  pr(true label)=0.585644\n",
      "truth=-1  pr(true label)=0.585644\n",
      "truth=-1  pr(true label)=0.50159\n",
      "truth=1  pr(true label)=0.414356\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.5841\n",
      "old error=5.3248   new error=5.2614  theta=[-0.00635825 -0.33962638]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 10\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.492414\n",
      "truth=-1  pr(true label)=0.607275\n",
      "truth=-1  pr(true label)=0.607275\n",
      "truth=-1  pr(true label)=0.507586\n",
      "truth=1  pr(true label)=0.392725\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.600014\n",
      "old error=5.2614   new error=5.21581  theta=[-0.03034728 -0.40552335]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 11\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.48834\n",
      "truth=-1  pr(true label)=0.624803\n",
      "truth=-1  pr(true label)=0.624803\n",
      "truth=-1  pr(true label)=0.51166\n",
      "truth=1  pr(true label)=0.375197\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.613806\n",
      "old error=5.21581   new error=5.18215  theta=[-0.04664764 -0.46333956]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 12\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.485785\n",
      "truth=-1  pr(true label)=0.639084\n",
      "truth=-1  pr(true label)=0.639084\n",
      "truth=-1  pr(true label)=0.514215\n",
      "truth=1  pr(true label)=0.360916\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.625865\n",
      "old error=5.18215   new error=5.15657  theta=[-0.05687464 -0.5145179 ]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 13\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.484428\n",
      "truth=-1  pr(true label)=0.65079\n",
      "truth=-1  pr(true label)=0.65079\n",
      "truth=-1  pr(true label)=0.515572\n",
      "truth=1  pr(true label)=0.34921\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.6365\n",
      "old error=5.15657   new error=5.13655  theta=[-0.06230634 -0.56020608]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 14\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.484017\n",
      "truth=-1  pr(true label)=0.660444\n",
      "truth=-1  pr(true label)=0.660444\n",
      "truth=-1  pr(true label)=0.515983\n",
      "truth=1  pr(true label)=0.339556\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.645958\n",
      "old error=5.13655   new error=5.12043  theta=[-0.06395511 -0.60131913]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 15\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.484349\n",
      "truth=-1  pr(true label)=0.668457\n",
      "truth=-1  pr(true label)=0.668457\n",
      "truth=-1  pr(true label)=0.515651\n",
      "truth=1  pr(true label)=0.331543\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.654435\n",
      "old error=5.12043   new error=5.10712  theta=[-0.06262519 -0.63859007]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 16\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.485265\n",
      "truth=-1  pr(true label)=0.675149\n",
      "truth=-1  pr(true label)=0.675149\n",
      "truth=-1  pr(true label)=0.514735\n",
      "truth=1  pr(true label)=0.324851\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.662087\n",
      "old error=5.10712   new error=5.09585  theta=[-0.05895781 -0.67260946]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 17\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.486637\n",
      "truth=-1  pr(true label)=0.680772\n",
      "truth=-1  pr(true label)=0.680772\n",
      "truth=-1  pr(true label)=0.513363\n",
      "truth=1  pr(true label)=0.319228\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.669042\n",
      "old error=5.09585   new error=5.08612  theta=[-0.05346604 -0.70385601]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0.05346604, -0.70385601])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEKCAYAAAD5MJl4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3XucVXW9//HXZxgQBhUVRkSQGW9h6VEuoz9I8xLqT32k\nWKmMjscLdpC8oR6Px7JjZmFaWWl2UNJMa7wkopJ5TTMtExsQFEMUFRAUxduAjKjI5/zxXRObfYE9\nw6y99uX9fDzWY6+91nev/WGz2R/W92rujoiISKqqpAMQEZHio+QgIiIZlBxERCSDkoOIiGRQchAR\nkQxKDiIikkHJQUREMig5iIhIBiUHERHJUJ10AB3Vr18/r6+vTzoMEZGSMnPmzHfcvTbf8iWXHOrr\n62lpaUk6DBGRkmJmizpSXtVKIiKSQclBREQyKDmIiEgGJQcREcmg5CAiIhkqIjk0N0N9PVRVhcfm\n5qQjEhEpbiXXlbWjmpth/HhoawvPFy0KzwGampKLS0SkmJX9ncPFF69LDO3a2sJxERHJruyTw+LF\nHTsuIiIVkBwGD+7YcRERqYDkMGkS1NSsf6xXr3BcRESyK/vk0NQEU6ZAXR2YhWP/8R9qjBYR2ZCy\nTw4QEsHChfDpp9C/P7zxRtIRiYgUt4pIDu26dYNjj4X77oOVK5OORkSkeFVUcgBobITVq2H69KQj\nEREpXhWXHEaNgkGD4Pbbk45ERKR4xZoczOw8M3vBzOaa2W1m1jPt/ClmttzMZkfbN+KMB8IUGmPH\nwkMPwfvvx/1uIiKlKbbkYGYDgXOABnffA+gGNGYpeoe7D422G+KKJ1VjY2icvvvuQrybiEjpibta\nqRroZWbVQA1QFP2ERoyAnXdW1ZKISC6xJQd3Xwr8BFgMvAm0uvvDWYp+3cyeM7OpZrZDXPGkMgt3\nD48+Cm+/XYh3FBEpLXFWK20NjAF2BLYHepvZiWnF/gDUu/uewCPAzTmuNd7MWsysZfny5V0S39ix\nsHYtTJ3aJZcTESkrcVYrHQy85u7L3f1TYBrwxdQC7v6uu38cPb0BGJHtQu4+xd0b3L2htra2S4Lb\nYw/4whdUtSQikk2cyWExMNLMaszMgNHAvNQCZjYg5elR6efj1F619Ne/wpIlhXpXEZHSEGebwwxg\nKjALeD56rylmdpmZHRUVOyfq6jqH0LPplLjiyWbsWHCHO+8s5LuKiBQ/c/ekY+iQhoYGb2lp6bLr\njRgB1dUwY0aXXVJEpOiY2Ux3b8i3fMWNkE43diw88wy8+mrSkYiIFI+KTw7HHRce77gj2ThERIpJ\nxSeH+vow35KSg4jIOhWfHCD0WpozB+YVrK+UiEhxU3IgrPFgprsHEZF2Sg7AgAFwwAFhQFyJdd4S\nEYmFkkOksRHmzw/VSyIilU7JIfL1r4dlRDWdhoiIksO/9OsHhxwS2h1UtSQilU7JIUVjIyxcGAbF\niYhUMiWHFEcfDT16qGpJRETJIUWfPnD44aFq6bPPko5GRCQ5Sg5pGhvhzTfDVN4iIpVKySHNkUdC\nTY0GxIlIZVNySNO7d0gQd94Ja9YkHY2ISDKUHLJobIR33oHHHks6EhGRZCg5ZHHYYbDlluq1JCKV\nS8khi549Q7fWadPg44+TjkZEpPBiTQ5mdl60RvRcM7vNzHqmnd/MzO4wswVmNsPM6uOMpyMaG6G1\nFR56KOlIREQKL7bkYGYDgXOABnffA+gGNKYVOw143913AX4GXBlXPB118MGwzTbqtSQilSnuaqVq\noJeZVQM1wBtp58cAN0f7U4HRZmYxx5SX7t3hmGPg3nuhrS3paERECiu25ODuS4GfAIuBN4FWd384\nrdhA4PWo/BqgFegbV0wdNXYsrFoFf/xj0pGIiBRWnNVKWxPuDHYEtgd6m9mJnbzWeDNrMbOW5cuX\nd2WYG3TAAdC/v3otiUjlibNa6WDgNXdf7u6fAtOAL6aVWQrsABBVPfUB3k2/kLtPcfcGd2+ora2N\nMeT1desGxx0X7hxWrCjY24qIJC7O5LAYGGlmNVE7wmhgXlqZ6cDJ0f4xwGPuxbWaQmNj6M46fXrS\nkYiIFE6cbQ4zCI3Ms4Dno/eaYmaXmdlRUbEbgb5mtgA4H7gorng6a+RIGDxYVUsiUlmq47y4u38X\n+G7a4UtSzq8Gjo0zhk1VVRWqln7+c3jvvdC9VUSk3GmEdB4aG8MkfNOmJR2JiEhhKDnkYfhw2GUX\nVS2JSOVQcsiDWbh7+POf4a23ko5GRCR+Sg55amyEtWth6tSkIxERiZ+SQ5523z1sqloSkUqg5NAB\nn/98WFu6qgrq66G5OemIRETioeSQp+ZmuO++sO8OixbB+PFKECJSnpQc8nTxxbB69frH2trCcRGR\ncqPkkKfFizt2XESklCk55Gnw4I4dFxEpZUoOeZo0CWpq1j/Wq1c4LiJSbpQc8tTUBFOmQF1dGBQH\ncNRR4biISLlRcuiApiZYuDAMhjvoIHjqqTDnkohIuVFy6KRzzoHXX4d77kk6EhGRrqfk0ElHHgk7\n7ghXX510JCIiXU/JoZO6dYOzzgojpmfNSjoaEZGupeSwCcaNg969dfcgIuVHyWETbLUVnHJKmIxP\nU3mLSDmJLTmY2RAzm52yrTCzc9PKHGhmrSllLsl1vWJ19tnwySdw/fVJRyIi0nViSw7uPt/dh7r7\nUGAE0AbcnaXok+3l3P2yuOKJy5AhcNhhMHlySBIiIuWgUNVKo4FX3H1Rgd6voCZOhGXL4Pe/TzoS\nEZGuUajk0AjcluPcKDObY2YPmNnuBYqnSx16aLiDuPrqMJ23iEipiz05mFkP4CjgziynZwF17r4X\n8Asg65AyMxtvZi1m1rJ8+fL4gu2kqqowKK6lBZ5+OuloREQ2XSHuHA4HZrl7Rn8ed1/h7h9G+/cD\n3c2sX5ZyU9y9wd0bamtr44+4E046Cfr0UbdWESkPhUgOx5OjSsnMtjML09iZ2T5RPO8WIKYut/nm\ncNppMHUqLFmSdDQiIpsm1uRgZr2BQ4BpKccmmNmE6OkxwFwzmwNcAzS6l26t/VlnhTaH//3fpCMR\nEdk0Vmq/xQ0NDd7S0pJ0GDl99avw5JNhUr5evZKORkQkMLOZ7t6Qb3mNkO5iEyfCu+/CrbcmHYmI\nSOcpOXSxAw6APfdUt1YRKW1KDl3MLHRrff55ePzxpKMREekcJYcYnHAC9O2rbq0iUrqUHGLQqxec\nfjpMnw6vvpp0NCIiHafkEJMzzggLAv3yl0lHIiLScUoOMRk4EI45Bm68ET78MOloREQ6RskhRuec\nA62tcPPNSUciItIxSg4xGjkS9t4brrkG1q5NOhoRkfwpOcTILAyKe+kleOihpKMREcmfkkPMjj0W\nBgwIdw8iIqVCySFmPXrAN78JDz4IL76YdDQiIvlRciiA8eNDkvjFL5KOREQkP0oOBdC/Pxx/fOi1\n9MEHSUcjIrJxSg4FMnEirFoVxj2IiBQ7JYcCGTYMvvQluPZa+OyzpKMREdkwJYcCmjgRFi6EP/wh\n6UhERDZMyaGAxoyBwYM1W6uIFL+NJgcz62Zm5xUimHJXXQ1nnhnWeXjuuaSjERHJbaPJwd0/A47v\n6IXNbIiZzU7ZVpjZuWllzMyuMbMFZvacmQ3v6PuUmm98I0zprbsHESlm+VYr/c3MrjWzL5nZ8PZt\nQy9w9/nuPtTdhwIjgDbg7rRihwO7Rtt4YHIH4y8522wDo0bBr38NVVVQXw/NzUlHJSKyvuo8yw2N\nHi9LOebAl/N8/WjgFXdflHZ8DHCLuzvwtJltZWYD3P3NPK9bcpqb4amnwr47LFoUBskBNDUlF5eI\nSKq8koO7H7SJ79MI3Jbl+EDg9ZTnS6Jj6yUHMxtPuLNg8ODBmxhKsi6+GFavXv9YW1s4ruQgIsUi\nr2olM+tjZj81s5Zou8rM+uT52h7AUcCdnQ3S3ae4e4O7N9TW1nb2MkVh8eKOHRcRSUK+bQ6/BlYC\nx0XbCuCmPF97ODDL3d/Kcm4psEPK80HRsbKV68anxG+IRKTM5Jscdnb377r7q9H2PWCnPF97PNmr\nlACmAydFvZZGAq3l3N4AMGkS1NSsf6xbt3BcRKRY5JscPjKz/dqfmNm+wEcbe5GZ9QYOAaalHJtg\nZhOip/cDrwILgF8BZ+QZT8lqaoIpU6CuLiwG1KdPmE6jvj7pyERE1rHQUWgjhcz2Am4B2tsZ3gdO\ndveCD+VqaGjwlpaWQr9tbFatgiFDYLvt4JlnQvdWEZGuZmYz3b0h3/L5jJCuAoa4+17AnsCe7j4s\nicRQjnr3hiuvhJkzw5TeIiLFIJ8R0muBC6P9Fe6+IvaoKswJJ4SBcd/6FqzQpysiRSDfSow/mdkF\nZraDmW3TvsUaWQUxC9NpvPUWXH550tGIiOSfHMYCZwJPADOjrXwq/ovA3nvDKafAz34GCxYkHY2I\nVLp82xxOdPcd07Z8u7JKni6/PKw1fcEFSUciIpUu3zaHawsQS8UbMCBMo3HvvfDII0lHIyKVLN9q\npUfN7OtmZrFGI5x7Luy0E5x3HqxZk3Q0IlKp8k0OpwO/Bz6O1mVYaWbqVxODnj3hqqvghRfg+uuT\njkZEKlW+yaEPcArwA3ffEtidMPJZYjBmDIweDf/zP/Duu0lHIyKVKN/k8EtgJOtWhFuJ2iFiYwY/\n/zm0tsKllyYdjYhUonyTw/9z9zOB1QDu/j7QI7aohD32gAkTYPJkmDs36WhEpNLkmxw+NbNuhNXf\nMLNaYG1sUQkAl10GW24ZGqnzmAJLRKTL5JscriGs/7ytmU0C/gpoLG/M+vaF730PHn0Upk9POhoR\nqSR5zcoKYGa7EdaCNuBRd58XZ2C5lNusrBvz6acwdCh8/HHowbTZZklHJCKlqMtnZW3n7i+6+y/d\n/dqkEkMl6t49NE6/8kqYf0lEpBC0ekAJOOQQOOoo+P73YdmypKMRkUqg5FAifvKTULX07W8nHYmI\nVAIlhxKx666h19JNN8E//pF0NCJS7mJNDma2lZlNNbMXzWyemY1KO3+gmbWa2exouyTOeErdd74D\n226rrq0iEr+47xyuBh50992AvYBsDdlPuvvQaLss5nhK2pZbwg9/CE89BbffnnQ0IlLOYksOZtYH\n2B+4EcDdP3H3D+J6v0pxyikwYgRceCGsWpV0NCJSruK8c9gRWA7cZGbPmtkNZtY7S7lRZjbHzB4w\ns91jjKcsVFWFLq1LlsCPfpR0NCJSruJMDtXAcGCyuw8DVgEXpZWZBdS5+17AL4B7sl3IzMabWYuZ\ntSxfvjzGkEvDvvtCY2NIDosWJR2NiJSjOJPDEmCJu8+Ink8lJIt/cfcV7v5htH8/0N3M+qVfyN2n\nuHuDuzfU1tbGGHLpuPJK+Owz+MIXwt1EfT00NycdlYiUi9iSg7svA143syHRodHAP1PLmNl27avL\nmdk+UTxawSAPTz4ZHtvaQs+lRYtg/HglCBHpGnH3VjobaDaz54ChwOVmNsHMJkTnjwHmmtkcwuR+\njZ7vZE8V7uKLw7xLqdrawnERkU2V98R7xaLSJt7Lpaoq+1gHM1irydRFJE1sE+9JcRk8uGPHRUQ6\nQsmhRE2aBDU1mcfHji18LCJSfpQcSlRTE0yZAnV1oSpphx3CNmUKLFiQdHQiUuqUHEpYUxMsXBja\nGBYvhr/8JbRFjBkDK1cmHZ2IlDIlhzKy447w+9/D/Plw0klqmBaRzlNyKDOjR4e1H+65JywOJCLS\nGUoOZWjiRDj5ZLj00pAkREQ6SsmhDJnBddfB3nvDv/87/POfG3+NiEgqJYcy1bMnTJsGvXuHBur3\n3086IhEpJUoOZWzQILjrrjDv0gknhIn6RETyoeRQ5vbdF669Fh58EL797aSjEZFSUZ10ABK/8ePh\n2WfD+g9Dh8LxxycdkYgUO905VIirr4b99oPTTguJQkRkQ5QcKkSPHjB1KvTtC0cfDVpQT0Q2RMmh\ngvTvD3ffDW+/Dccem7kehIhIOyWHCtPQAL/6VZiH6fzzk45GRIqVGqQr0IknhnaHn/4Uhg2DceOS\njkhEio3uHCrUlVfCwQfDN78JTz+ddDQiUmxiTQ5mtpWZTTWzF81snpmNSjtvZnaNmS0ws+fMbHic\n8cg61dVw++0wcCAcdlgYMFdVBfX10NycdHQikrS47xyuBh50992AvYB5aecPB3aNtvHA5JjjkRR9\n+4YxEK2tsHRpWJN60aJwTAlCpLLFlhzMrA+wP3AjgLt/4u4fpBUbA9ziwdPAVmY2IK6YJNN112Ue\na2uDiy8ufCwiUjzivHPYEVgO3GRmz5rZDWbWO63MQOD1lOdLomNSIIsXd+y4iFSGOJNDNTAcmOzu\nw4BVwEWduZCZjTezFjNrWa7RW11q8ODsxwfo/k2kosWZHJYAS9x9RvR8KiFZpFoK7JDyfFB0bD3u\nPsXdG9y9oba2NpZgK9WkSVBTk3l85Ur1YhKpZLElB3dfBrxuZkOiQ6OB9GVnpgMnRb2WRgKt7v5m\nXDFJpqYmmDIF6urCIkF1dfDjH0NtLRx0UJhyQ0Qqj7l7fBc3GwrcAPQAXgVOBcYCuPt1ZmbAtcBh\nQBtwqru3bOiaDQ0N3tKywSLSBZYvD3MwPfUUXHEFXHhhSB4iUprMbKa7N+RbPtYR0u4+G0gP5rqU\n8w6cGWcM0jm1tfDoo3DqqXDRRfDyyzB5MnTvnnRkIlIImj5DcurZM4x32GUX+MEPYOHCUM201VZJ\nRyYicdP0GbJBVVXw/e/Db34DTzwRVpZ77bWkoxKRuCk5SF5OPhkeegjeeANGjoQZMzb+GhEpXUoO\nkreDDoK//x023xwOPFA9mUTKmZKDdMhuu4XxD8OGhQWDfvSjMCeTiJQXJQfpsNpaeOwxGDsW/vu/\nw0R9WlVOpLwoOUin9OwJt94aJui74QY44ojwWF+vqb9FyoG6skqnVVWFLq477wynnRbGRbRXMbVP\n/Q1hFLaIlBbdOcgmO/XUUNWU3vagqb9FSpeSg3SJXJPlaupvkdKk5CBdItfU3336wCefFDYWEdl0\nSg7SJbJN/d2tG3zwAfzbv8EDDyQTl4h0jpKDdIlsU3/ffDP88Y+hLeKII+DII2HBgqQjFZF8xDpl\ndxw0ZXfp+eQTuPpquOyysH/++aGhevPNk45MpHJ0dMpu3TlI7Hr0gP/6L3jpJWhsDOtDDBkSxkGU\n2P9NRCqGkoMUzIABoarp73+H7beHE0+E/faDmTOTjkxE0ik5SMG1z+p6441hEaG99w4D5nJ1hxWR\nwlNykERUVcG4caGq6dxz4aabYNddQ9vELbdoGg6RpKlBWorCvHkwcSI88kjo7ZT6taypCT2hNA2H\nSOcVVYO0mS00s+fNbLaZZfyim9mBZtYanZ9tZpfEGY8Ur89/PiwmpGk4RIpDISbeO8jd39nA+Sfd\n/SsFiEOKnBm8k+ObsmhRaJ/YddfCxiRSqdTmIEUl1zQcAJ/7HHz5y3DHHfDxx4WLSaQSxZ0cHHjY\nzGaa2fgcZUaZ2Rwze8DMds9WwMzGm1mLmbUsV5eWspZtGo6aGrj2Wrj8cli4MIyVGDRo3dgJEel6\nsTZIm9lAd19qZtsCjwBnu/sTKee3BNa6+4dmdgRwtbtvsOJADdLlr7k5tDEsXhzuJCZNWtcYvXYt\n/OlPoYH63nthzZqwnvXpp8NXvwqbbZZo6CJFq6gapN19afT4NnA3sE/a+RXu/mG0fz/Q3cz6xRmT\nFL+mpnCHsHZteEztpVRVBYceClOnwuuvh7uJRYvg+ONh4EC44AKYPz+UbW5Wl1iRzootOZhZbzPb\non0fOBSYm1ZmOzOzaH+fKJ5344pJyst228G3vhUm83v4YTjooDBOYrfdQu+nceNC4nBftzKdEoRI\nfuK8c+gP/NXM5gDPAH909wfNbIKZTYjKHAPMjcpcAzR6qQ28kMRVVcEhh8Cdd4a7iR/+MCSM9HUk\n1CVWJH8aBCdlqaoq96R+3/lOqJoaORK6dy9sXCJJKao2B5Gk5OoSu9lm4c5i//2hb184+miYPBle\neaWw8YkUOyUHKUu5usTeeGMYaDdtGpxwAsyZA2ecAbvsErYzzgi9oFasWPc6NWxLJVK1kpStDXWJ\nbece2iceeig0aj/2GKxaFZY4HTUqNHrfdx+sXr3uNZrrSUpRR6uVlBxEUnzySVhvoj1Z5FprYvvt\nYcmSMOWHSClQm4PIJujRAw44IIyfaGnJ/eP/xhuw9dZhAN7558NvfwsvvBAG5eWi6ikpJYWYeE+k\nZA0eHMZIpNtmGxg7FmbNguuug48+Csd79oQ994Thw2HYsPC4xx5w111hnEVbWyjXPu4CVD0lxUnV\nSiIb0Ny8/o86ZLY5rFkTRmU/+2xIFs8+G7bW1nC+ujrcgXz6aeb16+rCKHCRuKnNQaSL5dOwnc4d\nXnttXcK4/PLcZQ85JPSU2nnndY877ZTZ26qzsYiAkoNIUaqvz149VVMDu+8e1qr44IP1zw0cuH7C\nePNNuOEG9ZySzuloclCbg0gBTJq08eqp994Lg/EWLFj3uGAB3H8/LFuW/bptbWFG2vnzQzLZfvt1\n27bbhi652egORDZGdw4iBbIpP8gffghbbpl7SpD0dbchJIbttguJIjVxLFoEt9yy/oJJnb0DUZIp\nHapWEilTuaqm6urCHcayZaGLbfu2dGnm/vvv575+dXUY+NevX/atb991+1tuCbfeuvG7oXwpycRP\n1UoiZSpX1dSkSeGHfdCgsG3IRx9B797Z70DWrAljMF56CZ56Kkwz8tln2a9TXR3W21i7dv3jbW1w\n5pmhiqxPH9hqq7Cl7m+xRXifduk9wjalm6+STNdRchApEe0/cpvy49erV+6xG3V18Pjj6567h+64\n774bEkX6dsUV2d+jtRXOOSd3DGbhzqM9acyfn7kmeFsbnH12GLG+xRaw+ebrP7bv9+y5bqBiMSaZ\nUk5WqlYSqTD5jN3IR65qrsGDw+jy1tbQAyv9Mf3Yvfd2/s/Srdu6hLFsWfYR6ltsESZUrKkJd02p\nj9mOPfAA/Od/rhvYCJ37fLrqc26/1qYmGbU5iMhGdcWPTdxJZtAgePJJWLkyNMivXLn+fvqxm27K\n/R49emQu/tRR1dUwZEi4++rZMzymb6nHr7oqs3syhF5k06aFspttlv2xe/fcd0TQuc9ZyUFECqYU\nkkz7KPQ1a8J7tLWFmXfT99sfx43L/R5f+1q4o1i9Ojy2b+nPc7XV5MtsXaJYsSKzbSf1z5X/NZUc\nRKTElFKSyceaNWGU++uvZ57r3z9M1Lh6dWhrWb16/f30Y9dck/09zLInjVw6mhxw99g2YCHwPDAb\naMly3ghrRy8AngOGb+yaI0aMcBGRbH73O/e6Onez8Pi733XuGjU17qFJPmw1NR2/Vlddp65u/Wu0\nb3V1HbtOtt/gDW2FmLL7IHcf6tkz1uHArtE2HphcgHhEpEw1NYX/3a9dGx470zOoqSncbdTVhf+d\n19V1rhG5q66Ta1XDSZM6dp2OirVaycwWAg3u/k6O89cDj7v7bdHz+cCB7v5mrmuqWklEKk0SvZXi\nHufgwMNm5sD17j4l7fxAILVWbkl0LGdyEBGpNE1NhR8fEXdy2M/dl5rZtsAjZvaiuz/R0YuY2XhC\ntRODBw/u6hhFRCRNrG0O7r40enwbuBvYJ63IUmCHlOeDomPp15ni7g3u3lBbWxtXuCIiEoktOZhZ\nbzPbon0fOBSYm1ZsOnCSBSOB1g21N4iISGHEWa3UH7jbwjC/auBWd3/QzCYAuPt1wP3AEYSurG3A\nqTHGIyIieYotObj7q8BeWY5fl7LvwJlxxSAiIp1TciOkzWw5kGX8Yl76AVm71RYxxVwYpRZzqcUL\nirlQcsVc5+55N9qWXHLYFGbW0pF+vsVAMRdGqcVcavGCYi6Uroq5ECOkRUSkxCg5iIhIhkpLDukj\ntEuBYi6MUou51OIFxVwoXRJzRbU5iIhIfirtzkFERPJQlsnBzA4zs/lmtsDMLspyfjMzuyM6P8PM\n6gsf5Xrx7GBmfzazf5rZC2Y2MUuZA82s1cxmR9slScSaFtNCM3s+iidjqtxo5Ps10ef8nJkNTyLO\nlHiGpHx+s81shZmdm1Ym8c/ZzH5tZm+b2dyUY9uY2SNm9nL0uHWO154clXnZzE5OMN4fm9mL0d/7\n3Wa2VY7XbvA7VOCYLzWzpSl/90fkeO0Gf18KHPMdKfEuNLPZOV7b8c+5I4s/lMIGdANeAXYCegBz\ngC+klTkDuC7abwTuSDjmAUQLHQFbAC9liflA4L6kP9+0mBYC/TZw/gjgAcKiTiOBGUnHnPY9WUbo\n+11UnzOwPzAcmJty7EfARdH+RcCVWV63DfBq9Lh1tL91QvEeClRH+1dmizef71CBY74UuCCP780G\nf18KGXPa+auAS7rqcy7HO4d9gAXu/qq7fwLcDoxJKzMGuDnanwqMNmtfzrvw3P1Nd58V7a8E5hGm\nLi91Y4BbPHga2MrMBiQdVGQ08Iq7d3ZAZWw8zFz8Xtrh1O/szcDRWV76/4FH3P09d38feAQ4LLZA\nI9nidfeH3X1N9PRpwqSaRSPHZ5yPfH5fYrGhmKPfr+OA27rq/coxOeRaIyJrmegL3Ar0LUh0GxFV\ncQ0DZmQ5PcrM5pjZA2a2e0EDy659vY6Z0bTq6fL5u0hKI7n/IRXb5wzQ39dNSrmMMHdZumL9vMcR\n7iCz2dh3qNDOiqrCfp2j6q5YP+MvAW+5+8s5znf4cy7H5FCyzGxz4C7gXHdfkXZ6FqEKZC/gF8A9\nhY4vi/3cfThhudczzWz/pAPKh5n1AI4C7sxyuhg/5/V4qCcoiW6GZnYxsAZozlGkmL5Dk4GdgaGE\nBceuSjCWjjqeDd81dPhzLsfkkM8aEf8qY2bVQB/g3YJEl4OZdSckhmZ3n5Z+3t1XuPuH0f79QHcz\n61fgMNNj6pL1OhJwODDL3d9KP1GMn3PkrfYquejx7SxliurzNrNTgK8ATVFCy5DHd6hg3P0td//M\n3dcCv8oRS1F9xvCv37CvAXfkKtOZz7kck8M/gF3NbMfof4iNhHUjUk0H2ntyHAM8luvLWwhRfeGN\nwDx3/2l5spEEAAADJ0lEQVSOMtu1t4uY2T6Ev7vEEpqV9nodOf+XVWyfc4rU7+zJwL1ZyjwEHGpm\nW0dVIodGxwrOzA4DLgSOcve2HGXy+Q4VTFp72FdzxJLP70uhHQy86O5Lsp3s9OdciFb2Qm+EXjIv\nEXoVXBwdu4zwRQXoSahSWAA8A+yUcLz7EaoJngNmR9sRwARgQlTmLOAFQu+Ip4EvJhzzTlEsc6K4\n2j/n1JgN+GX09/A80FAE343ehB/7PinHiupzJiSuN4FPCXXapxHaxB4FXgb+BGwTlW0Abkh57bjo\ne70AODXBeBcQ6ubbv8/tvQO3B+7f0HcowZh/G31PnyP84A9Ijzl6nvH7klTM0fHftH9/U8pu8ues\nEdIiIpKhHKuVRERkEyk5iIhIBiUHERHJoOQgIiIZlBxERCSDkoNULDN7KnqsN7MTuvja3872XiKl\nQl1ZpeKZ2YGE2Ti/0oHXVPu6ieWynf/Q3TfvivhEkqA7B6lYZvZhtHsF8KVorvvzzKxbtB7BP6JJ\n2E6Pyh9oZk+a2XTgn9Gxe6LJzF5on9DMzK4AekXXa059r2i0+I/NbG40v/7YlGs/bmZTLayD0Jzk\nTMEi1UkHIFIELiLlziH6kW91973NbDPgb2b2cFR2OLCHu78WPR/n7u+ZWS/gH2Z2l7tfZGZnufvQ\nLO/1NcLEbnsB/aLXPBGdGwbsDrwB/A3YF/hr1/9xRTZOdw4imQ4lzAk1mzB1el9g1+jcMymJAeAc\nM2ufamOHlHK57Afc5mGCt7eAvwB7p1x7iYeJ32YD9V3ypxHpBN05iGQy4Gx3X2/SuqhtYlXa84OB\nUe7eZmaPE+bt6qyPU/Y/Q/8+JUG6cxCBlYTlWds9BHwzmkYdM/tcNJtluj7A+1Fi2I2wFGq7T9tf\nn+ZJYGzUrlFLWPrxmS75U4h0If3PRCTMwvlZVD30G+BqQpXOrKhReDnZl+V8EJhgZvOA+YSqpXZT\ngOfMbJa7N6UcvxsYRZgh04EL3X1ZlFxEioa6soqISAZVK4mISAYlBxERyaDkICIiGZQcREQkg5KD\niIhkUHIQEZEMSg4iIpJByUFERDL8H6+ZANg/7RUYAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110d3fc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "theta = npa([1.,1.])\n",
    "gradient_descent(gradient_logistic, nll, theta, \n",
    "                 .1, D, .01, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.731059\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.119203\n",
      "truth=-1  pr(true label)=0.268941\n",
      "truth=1  pr(true label)=0.880797\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.268941\n",
      "\n",
      "\n",
      "iteration 1\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.248896\n",
      "truth=-1  pr(true label)=0.922582\n",
      "truth=-1  pr(true label)=0.922582\n",
      "truth=-1  pr(true label)=0.751104\n",
      "truth=1  pr(true label)=0.0774179\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.797937\n",
      "old error=8.70686   new error=6.00865  theta=[-1.10450839 -1.37344981]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 2\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.541267\n",
      "truth=-1  pr(true label)=0.655278\n",
      "truth=-1  pr(true label)=0.655278\n",
      "truth=-1  pr(true label)=0.458733\n",
      "truth=1  pr(true label)=0.344722\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.691633\n",
      "old error=6.00865   new error=5.05853  theta=[ 0.16544566 -0.80776659]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 3\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.512184\n",
      "truth=-1  pr(true label)=0.750551\n",
      "truth=-1  pr(true label)=0.750551\n",
      "truth=-1  pr(true label)=0.487816\n",
      "truth=1  pr(true label)=0.249449\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.759566\n",
      "old error=5.05853   new error=5.01059  theta=[ 0.04874477 -1.15029945]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 4\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.568573\n",
      "truth=-1  pr(true label)=0.703297\n",
      "truth=-1  pr(true label)=0.703297\n",
      "truth=-1  pr(true label)=0.431427\n",
      "truth=1  pr(true label)=0.296703\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.757511\n",
      "old error=5.01059   new error=4.98827  theta=[ 0.27603109 -1.13907997]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "iteration 5\n",
      "truth=-1  pr(true label)=0.5\n",
      "truth=1  pr(true label)=0.561875\n",
      "truth=-1  pr(true label)=0.735537\n",
      "truth=-1  pr(true label)=0.735537\n",
      "truth=-1  pr(true label)=0.438125\n",
      "truth=1  pr(true label)=0.264463\n",
      "truth=1  pr(true label)=0.5\n",
      "truth=-1  pr(true label)=0.78103\n",
      "old error=4.98827   new error=4.97953  theta=[ 0.24877701 -1.27167751]\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.24877701, -1.27167751])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNjEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x114823da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# What if learning is large?\n",
    "theta = npa([1.,1.])\n",
    "gradient_descent(gradient_logistic, nll, theta,\n",
    "                 1, D, .01, 50)\n",
    "# In this case, we converge in fewer iterations.\n",
    "# For larger examples, we may have issues of stepping over the minimum."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
