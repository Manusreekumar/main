{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 579\n",
    "<br>\n",
    "\n",
    "## Clustering Words with K-Means\n",
    "\n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation\n",
    "\n",
    "Often, we want to know which features appear together.\n",
    "\n",
    "- If you liked *Twilight* you might like *Nosferatu*.\n",
    "- \"happy\" is a synonym of \"glad.\"\n",
    "\n",
    "Can be used to summarize a large collection of messages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use k-means to cluster together related words from Twitter.\n",
    "\n",
    "**Caution:** This uses live Twitter data, which often contains profanity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n"
     ]
    }
   ],
   "source": [
    "# Get some tweets containing the word 'i'.\n",
    "\n",
    "import os\n",
    "from TwitterAPI import TwitterAPI\n",
    "\n",
    "# Read Twitter credentials from environmental variables.\n",
    "api = TwitterAPI(os.environ.get('TW_CONSUMER_KEY'),\n",
    "                 os.environ.get('TW_CONSUMER_SECRET'),\n",
    "                 os.environ.get('TW_ACCESS_TOKEN'),\n",
    "                 os.environ.get('TW_ACCESS_TOKEN_SECRET'))\n",
    "\n",
    "# Collect 10000 tweets.\n",
    "tweets = []\n",
    "while True: \n",
    "    r = api.request('statuses/filter', {'track':'i',\n",
    "                                        'language':'en'})\n",
    "    if r.status_code != 200: # error\n",
    "        break\n",
    "    else:\n",
    "        for item in r.get_iterator():\n",
    "            tweets.append(item)\n",
    "            if len(tweets) > 10000:\n",
    "                break\n",
    "            elif len(tweets) % 100 == 0:\n",
    "                print(len(tweets))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10006\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text RT @theMasonRamsey: Yes I am the real Mason Ramsey https://t.co/VU6CYSaN6c\n",
      "description: None\n",
      "name: ðŸ‡²ðŸ‡½ðŸ–¤\n",
      "location: Alief,TX\n"
     ]
    }
   ],
   "source": [
    "# Each tweet is a Python dict.\n",
    "print('text', tweets[0]['text'])\n",
    "print('description:', tweets[0]['user']['description'])\n",
    "print('name:', tweets[0]['user']['name'])\n",
    "print('location:', tweets[0]['user']['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = [t for t in tweets if 'text' in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9238"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt', 'yes', 'i', 'am', 'the', 'real', 'mason', 'ramsey']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tokenize each tweet text.\n",
    "import re\n",
    "tokens = []\n",
    "for tweet in tweets:\n",
    "    text = tweet['text'].lower()\n",
    "    text = re.sub('@\\S+', ' ', text)  # Remove mentions.\n",
    "    text = re.sub('http\\S+', ' ', text)  # Remove urls.\n",
    "    tokens.append(re.findall('[A-Za-z]+', text)) # Retain words.\n",
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count words.\n",
    "from collections import Counter\n",
    "\n",
    "word_counts = Counter()\n",
    "for tweet in tokens:\n",
    "    word_counts.update(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12763 unique terms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('i', 10975),\n",
       " ('rt', 4808),\n",
       " ('the', 3709),\n",
       " ('to', 3538),\n",
       " ('a', 3049),\n",
       " ('you', 2375),\n",
       " ('and', 2342),\n",
       " ('my', 1919),\n",
       " ('m', 1843),\n",
       " ('t', 1587)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect word counts.\n",
    "import math\n",
    "\n",
    "print(len(word_counts), 'unique terms')\n",
    "word_counts.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3957 words occur at least three times.\n"
     ]
    }
   ],
   "source": [
    "# Retain in vocabulary words occurring more than twice.\n",
    "vocab = set([w for w, c in word_counts.items() if c > 2])\n",
    "print('%d words occur at least three times.' % len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prune tokens.\n",
    "newtoks = []\n",
    "for i, tweet in enumerate(tokens):\n",
    "    newtok = [token for token in tweet if token in vocab]\n",
    "    if len(newtok) > 0:\n",
    "        newtoks.append(newtok)\n",
    "tokens = newtoks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt', 'yes', 'i', 'am', 'the', 'real', 'mason', 'ramsey']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A sample pruned tweet.\n",
    "tokens[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['yourself',\n",
       " 'a',\n",
       " 'common',\n",
       " 'interview',\n",
       " 'question',\n",
       " 'i',\n",
       " 'find',\n",
       " 'that',\n",
       " 'to',\n",
       " 'be',\n",
       " 'the',\n",
       " 'first',\n",
       " 'ice',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'chance',\n",
       " 'to']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Context features**\n",
    "\n",
    "To determine if two words are similar, we will create a feature vector that counts how often other words appear nearby.\n",
    "\n",
    "E.g.,\n",
    "\n",
    "> I really **love** school.\n",
    "\n",
    "> I really **like** school.\n",
    "\n",
    "> You **love** school.\n",
    "\n",
    "**love:** {really@-1: 1, school@1: 1, you@-1: 1}\n",
    "\n",
    "**like:** {really@-1: 1, school@1: 1}\n",
    "\n",
    "<br>\n",
    "\n",
    "**Assumption**: words with similar meaning have similar contexts vectors.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context for word am in ['rt', 'yes', 'i', 'am', 'the', 'real', 'mason', 'ramsey']\n",
      "['yes@-2', 'i@-1', 'the@1', 'real@2']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "def get_contexts(tweet, i, window):\n",
    "    \"\"\"\n",
    "    Get the context features for token at position i\n",
    "    in this tweet, using the given window size.\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    for j in range(np.amax([0, i-window]), i):\n",
    "        features.append(tweet[j] + \"@\" + str(j-i))\n",
    "    for j in range(i+1, min(i + window + 1, len(tweet))):\n",
    "        features.append(tweet[j] + \"@\" + str(j-i))\n",
    "    return features\n",
    "\n",
    "print('context for word %s in %s' % (tokens[0][3], tokens[0]))\n",
    "print(get_contexts(tokens[0], i=3, window=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Q: How would the approach differ if we ignore location of context?**\n",
    "\n",
    "E.g., **love:** {really: 1, school:1, you: 1} **vs** {really@-1: 1, school@1: 1, you@-1: 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each term, create a context vector, indicating how often\n",
    "# each word occurs to the left or right of it.\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "# dict from term to context vector.\n",
    "contexts = defaultdict(lambda: Counter())\n",
    "window = 2\n",
    "for tweet in tokens:\n",
    "    for i, token in enumerate(tweet):\n",
    "        features = get_contexts(tweet, i, window)\n",
    "        contexts[token].update(features)\n",
    "        # Optionally: ignore word order\n",
    "        # contexts[token].update(tweet[:i] + tweet[i+1:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('m@1', 1790),\n",
       " ('rt@-1', 1612),\n",
       " ('t@2', 761),\n",
       " ('a@2', 551),\n",
       " ('to@2', 473),\n",
       " ('rt@-2', 438),\n",
       " ('and@-1', 410),\n",
       " ('love@1', 406),\n",
       " ('can@1', 383),\n",
       " ('ve@1', 361),\n",
       " ('you@2', 345),\n",
       " ('have@1', 341),\n",
       " ('just@1', 328),\n",
       " ('don@1', 313),\n",
       " ('was@1', 305),\n",
       " ('am@1', 301),\n",
       " ('the@2', 281),\n",
       " ('but@-1', 274),\n",
       " ('when@-1', 257),\n",
       " ('the@-2', 256)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts['i'].most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**tf-idf vectors**\n",
    "\n",
    "- We will transform the context features by dividing by (the log of) the number of distinct terms this feature appears in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i@-1', 10854),\n",
       " ('i@-2', 10507),\n",
       " ('i@1', 9005),\n",
       " ('i@2', 6890),\n",
       " ('rt@-1', 4779)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute the number of different contexts each term appears in.\n",
    "# Actually: this is the total number of times this context feature appears.\n",
    "tweet_freq = Counter()\n",
    "for context in contexts.values():\n",
    "    tweet_freq.update(context)\n",
    "tweet_freq.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 256,\n",
       "         2: 778,\n",
       "         3: 3419,\n",
       "         4: 2030,\n",
       "         5: 1316,\n",
       "         6: 946,\n",
       "         7: 751,\n",
       "         8: 602,\n",
       "         9: 446,\n",
       "         10: 398,\n",
       "         11: 330,\n",
       "         12: 281,\n",
       "         13: 273,\n",
       "         14: 249,\n",
       "         15: 158,\n",
       "         16: 161,\n",
       "         17: 127,\n",
       "         18: 114,\n",
       "         19: 126,\n",
       "         20: 128,\n",
       "         21: 117,\n",
       "         22: 96,\n",
       "         23: 95,\n",
       "         24: 86,\n",
       "         25: 77,\n",
       "         26: 62,\n",
       "         27: 57,\n",
       "         28: 60,\n",
       "         29: 59,\n",
       "         30: 55,\n",
       "         31: 63,\n",
       "         32: 49,\n",
       "         33: 57,\n",
       "         34: 53,\n",
       "         35: 40,\n",
       "         36: 22,\n",
       "         37: 34,\n",
       "         38: 36,\n",
       "         39: 36,\n",
       "         40: 17,\n",
       "         41: 26,\n",
       "         42: 23,\n",
       "         43: 39,\n",
       "         44: 25,\n",
       "         45: 20,\n",
       "         46: 23,\n",
       "         47: 28,\n",
       "         48: 35,\n",
       "         49: 29,\n",
       "         50: 18,\n",
       "         51: 23,\n",
       "         52: 23,\n",
       "         53: 19,\n",
       "         54: 15,\n",
       "         55: 14,\n",
       "         56: 19,\n",
       "         57: 17,\n",
       "         58: 27,\n",
       "         59: 17,\n",
       "         60: 11,\n",
       "         61: 22,\n",
       "         62: 21,\n",
       "         63: 17,\n",
       "         64: 20,\n",
       "         65: 16,\n",
       "         66: 11,\n",
       "         67: 15,\n",
       "         68: 8,\n",
       "         69: 15,\n",
       "         70: 9,\n",
       "         71: 15,\n",
       "         72: 8,\n",
       "         73: 13,\n",
       "         74: 10,\n",
       "         75: 19,\n",
       "         76: 13,\n",
       "         77: 12,\n",
       "         78: 13,\n",
       "         79: 7,\n",
       "         80: 10,\n",
       "         81: 8,\n",
       "         82: 8,\n",
       "         83: 10,\n",
       "         84: 9,\n",
       "         85: 11,\n",
       "         86: 10,\n",
       "         87: 13,\n",
       "         88: 16,\n",
       "         89: 9,\n",
       "         90: 10,\n",
       "         91: 10,\n",
       "         92: 8,\n",
       "         93: 10,\n",
       "         94: 6,\n",
       "         95: 5,\n",
       "         96: 3,\n",
       "         97: 8,\n",
       "         98: 5,\n",
       "         99: 3,\n",
       "         100: 10,\n",
       "         101: 4,\n",
       "         102: 7,\n",
       "         103: 4,\n",
       "         104: 2,\n",
       "         105: 6,\n",
       "         106: 7,\n",
       "         107: 2,\n",
       "         108: 1,\n",
       "         109: 5,\n",
       "         110: 7,\n",
       "         111: 2,\n",
       "         112: 5,\n",
       "         113: 5,\n",
       "         114: 5,\n",
       "         115: 1,\n",
       "         116: 3,\n",
       "         117: 9,\n",
       "         118: 2,\n",
       "         119: 1,\n",
       "         120: 1,\n",
       "         121: 3,\n",
       "         122: 6,\n",
       "         123: 11,\n",
       "         124: 6,\n",
       "         125: 4,\n",
       "         126: 4,\n",
       "         127: 3,\n",
       "         128: 2,\n",
       "         129: 6,\n",
       "         130: 2,\n",
       "         131: 4,\n",
       "         132: 4,\n",
       "         133: 2,\n",
       "         134: 4,\n",
       "         135: 1,\n",
       "         136: 3,\n",
       "         137: 4,\n",
       "         138: 3,\n",
       "         139: 3,\n",
       "         140: 5,\n",
       "         141: 1,\n",
       "         142: 2,\n",
       "         143: 2,\n",
       "         144: 3,\n",
       "         145: 1,\n",
       "         146: 7,\n",
       "         147: 1,\n",
       "         148: 2,\n",
       "         149: 1,\n",
       "         150: 2,\n",
       "         151: 1,\n",
       "         152: 1,\n",
       "         153: 1,\n",
       "         154: 1,\n",
       "         155: 2,\n",
       "         156: 2,\n",
       "         157: 1,\n",
       "         158: 2,\n",
       "         159: 2,\n",
       "         160: 3,\n",
       "         161: 2,\n",
       "         162: 3,\n",
       "         163: 2,\n",
       "         164: 2,\n",
       "         165: 1,\n",
       "         166: 2,\n",
       "         167: 2,\n",
       "         168: 6,\n",
       "         169: 1,\n",
       "         171: 4,\n",
       "         172: 2,\n",
       "         174: 1,\n",
       "         175: 1,\n",
       "         179: 1,\n",
       "         180: 2,\n",
       "         181: 2,\n",
       "         182: 2,\n",
       "         184: 2,\n",
       "         185: 1,\n",
       "         186: 3,\n",
       "         187: 2,\n",
       "         188: 3,\n",
       "         189: 1,\n",
       "         190: 5,\n",
       "         191: 2,\n",
       "         192: 2,\n",
       "         193: 3,\n",
       "         194: 1,\n",
       "         195: 3,\n",
       "         196: 2,\n",
       "         199: 2,\n",
       "         201: 2,\n",
       "         202: 2,\n",
       "         203: 3,\n",
       "         205: 1,\n",
       "         206: 1,\n",
       "         207: 3,\n",
       "         208: 1,\n",
       "         209: 2,\n",
       "         211: 1,\n",
       "         212: 1,\n",
       "         214: 3,\n",
       "         215: 4,\n",
       "         217: 4,\n",
       "         218: 1,\n",
       "         221: 1,\n",
       "         222: 2,\n",
       "         224: 2,\n",
       "         225: 1,\n",
       "         227: 3,\n",
       "         228: 1,\n",
       "         230: 1,\n",
       "         231: 4,\n",
       "         232: 1,\n",
       "         233: 1,\n",
       "         235: 3,\n",
       "         236: 1,\n",
       "         237: 4,\n",
       "         238: 3,\n",
       "         239: 2,\n",
       "         240: 2,\n",
       "         241: 3,\n",
       "         242: 3,\n",
       "         243: 2,\n",
       "         244: 3,\n",
       "         246: 2,\n",
       "         247: 1,\n",
       "         248: 3,\n",
       "         249: 1,\n",
       "         250: 3,\n",
       "         251: 2,\n",
       "         252: 1,\n",
       "         253: 1,\n",
       "         254: 1,\n",
       "         255: 1,\n",
       "         256: 2,\n",
       "         258: 1,\n",
       "         259: 1,\n",
       "         261: 4,\n",
       "         262: 1,\n",
       "         263: 2,\n",
       "         265: 1,\n",
       "         267: 1,\n",
       "         268: 2,\n",
       "         271: 2,\n",
       "         273: 1,\n",
       "         274: 1,\n",
       "         275: 1,\n",
       "         277: 1,\n",
       "         278: 1,\n",
       "         280: 2,\n",
       "         282: 2,\n",
       "         283: 3,\n",
       "         286: 1,\n",
       "         287: 1,\n",
       "         289: 1,\n",
       "         292: 2,\n",
       "         296: 1,\n",
       "         298: 1,\n",
       "         299: 1,\n",
       "         301: 1,\n",
       "         302: 1,\n",
       "         305: 2,\n",
       "         307: 2,\n",
       "         309: 1,\n",
       "         310: 1,\n",
       "         311: 1,\n",
       "         314: 2,\n",
       "         316: 1,\n",
       "         329: 2,\n",
       "         332: 1,\n",
       "         334: 1,\n",
       "         335: 2,\n",
       "         337: 1,\n",
       "         338: 1,\n",
       "         339: 1,\n",
       "         345: 1,\n",
       "         346: 1,\n",
       "         347: 1,\n",
       "         348: 1,\n",
       "         349: 1,\n",
       "         350: 1,\n",
       "         352: 2,\n",
       "         353: 3,\n",
       "         354: 1,\n",
       "         355: 1,\n",
       "         356: 1,\n",
       "         358: 1,\n",
       "         359: 1,\n",
       "         360: 2,\n",
       "         361: 2,\n",
       "         363: 1,\n",
       "         364: 2,\n",
       "         365: 1,\n",
       "         369: 2,\n",
       "         370: 1,\n",
       "         371: 1,\n",
       "         374: 1,\n",
       "         376: 1,\n",
       "         377: 1,\n",
       "         379: 1,\n",
       "         380: 1,\n",
       "         381: 1,\n",
       "         383: 2,\n",
       "         392: 3,\n",
       "         393: 1,\n",
       "         394: 1,\n",
       "         395: 1,\n",
       "         399: 1,\n",
       "         400: 1,\n",
       "         401: 1,\n",
       "         403: 1,\n",
       "         406: 2,\n",
       "         408: 1,\n",
       "         410: 1,\n",
       "         412: 1,\n",
       "         414: 2,\n",
       "         419: 2,\n",
       "         423: 1,\n",
       "         425: 1,\n",
       "         426: 1,\n",
       "         428: 1,\n",
       "         429: 2,\n",
       "         431: 2,\n",
       "         432: 2,\n",
       "         435: 1,\n",
       "         438: 1,\n",
       "         439: 3,\n",
       "         440: 1,\n",
       "         443: 1,\n",
       "         446: 2,\n",
       "         448: 1,\n",
       "         449: 2,\n",
       "         450: 2,\n",
       "         455: 1,\n",
       "         459: 2,\n",
       "         461: 1,\n",
       "         462: 1,\n",
       "         465: 1,\n",
       "         467: 1,\n",
       "         470: 1,\n",
       "         474: 2,\n",
       "         487: 1,\n",
       "         494: 2,\n",
       "         496: 1,\n",
       "         498: 1,\n",
       "         500: 2,\n",
       "         514: 1,\n",
       "         516: 1,\n",
       "         530: 1,\n",
       "         536: 1,\n",
       "         549: 1,\n",
       "         574: 1,\n",
       "         577: 1,\n",
       "         581: 1,\n",
       "         586: 1,\n",
       "         589: 1,\n",
       "         591: 1,\n",
       "         592: 1,\n",
       "         598: 1,\n",
       "         617: 1,\n",
       "         619: 1,\n",
       "         625: 1,\n",
       "         633: 1,\n",
       "         637: 1,\n",
       "         639: 1,\n",
       "         649: 1,\n",
       "         657: 1,\n",
       "         664: 1,\n",
       "         676: 1,\n",
       "         682: 1,\n",
       "         704: 1,\n",
       "         723: 2,\n",
       "         728: 1,\n",
       "         730: 1,\n",
       "         736: 1,\n",
       "         753: 1,\n",
       "         754: 1,\n",
       "         757: 2,\n",
       "         758: 1,\n",
       "         762: 1,\n",
       "         766: 1,\n",
       "         771: 1,\n",
       "         777: 2,\n",
       "         780: 1,\n",
       "         781: 1,\n",
       "         788: 1,\n",
       "         796: 1,\n",
       "         807: 1,\n",
       "         814: 1,\n",
       "         823: 1,\n",
       "         831: 1,\n",
       "         844: 1,\n",
       "         860: 1,\n",
       "         871: 1,\n",
       "         888: 1,\n",
       "         896: 1,\n",
       "         904: 1,\n",
       "         948: 1,\n",
       "         995: 2,\n",
       "         1027: 1,\n",
       "         1058: 1,\n",
       "         1064: 1,\n",
       "         1076: 1,\n",
       "         1084: 1,\n",
       "         1112: 1,\n",
       "         1170: 1,\n",
       "         1184: 1,\n",
       "         1185: 1,\n",
       "         1193: 1,\n",
       "         1195: 1,\n",
       "         1202: 1,\n",
       "         1226: 1,\n",
       "         1247: 1,\n",
       "         1250: 1,\n",
       "         1251: 1,\n",
       "         1259: 1,\n",
       "         1271: 1,\n",
       "         1273: 1,\n",
       "         1277: 1,\n",
       "         1292: 1,\n",
       "         1295: 1,\n",
       "         1301: 1,\n",
       "         1304: 1,\n",
       "         1307: 1,\n",
       "         1328: 1,\n",
       "         1340: 1,\n",
       "         1351: 1,\n",
       "         1356: 1,\n",
       "         1366: 1,\n",
       "         1377: 1,\n",
       "         1396: 1,\n",
       "         1420: 1,\n",
       "         1434: 1,\n",
       "         1475: 1,\n",
       "         1504: 1,\n",
       "         1517: 1,\n",
       "         1530: 1,\n",
       "         1540: 1,\n",
       "         1543: 1,\n",
       "         1544: 1,\n",
       "         1560: 1,\n",
       "         1570: 1,\n",
       "         1572: 1,\n",
       "         1587: 1,\n",
       "         1632: 1,\n",
       "         1652: 1,\n",
       "         1707: 1,\n",
       "         1788: 1,\n",
       "         1843: 1,\n",
       "         1866: 1,\n",
       "         1875: 1,\n",
       "         2029: 1,\n",
       "         2099: 1,\n",
       "         2175: 1,\n",
       "         2197: 1,\n",
       "         2270: 1,\n",
       "         2272: 1,\n",
       "         2306: 1,\n",
       "         2310: 1,\n",
       "         2683: 1,\n",
       "         2906: 1,\n",
       "         2948: 1,\n",
       "         3025: 1,\n",
       "         3167: 1,\n",
       "         3274: 1,\n",
       "         3448: 1,\n",
       "         3472: 1,\n",
       "         3473: 1,\n",
       "         3527: 1,\n",
       "         3592: 1,\n",
       "         3644: 1,\n",
       "         4766: 1,\n",
       "         4779: 1,\n",
       "         6890: 1,\n",
       "         9005: 1,\n",
       "         10507: 1,\n",
       "         10854: 1})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(tweet_freq.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i@2', 1330),\n",
       " ('i@1', 1288),\n",
       " ('i@-2', 1256),\n",
       " ('the@-1', 1096),\n",
       " ('and@1', 933)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# As opposed to the above, this computes the number of unique terms that this feature\n",
    "# appears in. Q: How do you expect to affect the output?\n",
    "tweet_freq_2 = Counter()\n",
    "for context in contexts.values():\n",
    "    tweet_freq_2.update(context.keys())\n",
    "tweet_freq_2.most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('m@1', 0.5511605454669377),\n",
       " ('rt@-1', 0.44642171936297137),\n",
       " ('t@2', 0.23899707634438072),\n",
       " ('a@2', 0.16079304530543112),\n",
       " ('love@1', 0.14318770023761604)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transform each context vector to be term freq / tweet frequency. \n",
    "# Also then normalize by length.\n",
    "for term, context in contexts.items():\n",
    "    for term2, frequency in context.items():\n",
    "        # tf / [ 1 + log(df) ]\n",
    "        context[term2] = frequency / (1. + math.log(tweet_freq[term2]))\n",
    "    length = math.sqrt(sum([v*v for v in context.values()]))\n",
    "    for term2, frequency in context.items():\n",
    "        context[term2] = 1. * frequency / length\n",
    "    \n",
    "contexts['i'].most_common(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('high@-1', 0.33410017477798243),\n",
       " ('middle@-1', 0.31465991108735275),\n",
       " ('at@-1', 0.26749252152079955),\n",
       " ('of@-1', 0.23182846238255211),\n",
       " ('sick@-2', 0.2246190640179431),\n",
       " ('i@2', 0.19616667753883338),\n",
       " ('in@-2', 0.1763260756319353),\n",
       " ('shit@2', 0.15553285234615388),\n",
       " ('graduating@-2', 0.14247533632849224),\n",
       " ('and@1', 0.13792546407585593)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts['school'].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i@-1', 0.8547243969778506),\n",
       " ('you@1', 0.29242881848427854),\n",
       " ('rt@-2', 0.1944978477641765),\n",
       " ('i@-2', 0.10559498057118918),\n",
       " ('so@2', 0.09870444112740873),\n",
       " ('this@1', 0.08385902973871077),\n",
       " ('him@1', 0.07599052784866119),\n",
       " ('in@-1', 0.07280605299458265),\n",
       " ('the@1', 0.07064898763556308),\n",
       " ('to@1', 0.06617376598304402)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts['love'].most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i@-1', 0.7461742331051283),\n",
       " ('rt@-2', 0.3454380166083687),\n",
       " ('broke@2', 0.21714974804128767),\n",
       " ('i@-2', 0.1594107231050546),\n",
       " ('my@1', 0.14994363863091223),\n",
       " ('ikea@1', 0.14483056224152382),\n",
       " ('when@1', 0.13738893905677277),\n",
       " ('fucking@-1', 0.1168426840411504),\n",
       " ('you@1', 0.10572992887476061),\n",
       " ('asshole@1', 0.09655370816101587)]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "contexts['hate'].most_common(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point we have a list of dictionaries, one per term, indicating the terms that co-occur (weighted by inverse tweet frequency).\n",
    "\n",
    "Next, we have to cluster these vectors. To do this, we'll need to be able to compute the euclidean distance between two vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730951\n",
      "2.23606797749979\n"
     ]
    }
   ],
   "source": [
    "# n.b. This is not efficient!\n",
    "def distance(c1, c2):\n",
    "    if len(c1.keys()) == 0 or len(c2.keys()) == 0:\n",
    "        return 1e9\n",
    "    keys = set(c1.keys()) | set(c2.keys())\n",
    "    distance = 0.\n",
    "    for k in keys:\n",
    "        distance += (c1[k] - c2[k]) ** 2\n",
    "    return math.sqrt(distance)\n",
    "\n",
    "print(distance({'hi':10, 'bye': 5}, {'hi': 9, 'bye': 4}))\n",
    "print(distance({'hi':10, 'bye': 5}, {'hi': 8, 'bye': 4}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['love', 'm', 'hope', 'am', 'hate', 'guess', 'll', 'think', 'saw',\n",
       "       'swear'],\n",
       "      dtype='<U31')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def find_closest(term, n=5):\n",
    "    terms = np.array(list(contexts.keys()))\n",
    "    context = contexts[term]\n",
    "    distances = []\n",
    "    for term2, context2 in contexts.items():\n",
    "        distances.append(distance(context, context2))\n",
    "    return terms[np.argsort(distances)][:n]\n",
    "\n",
    "find_closest('love', n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3957 nonzero contexts\n"
     ]
    }
   ],
   "source": [
    "nz_contexts = [t for t, context in contexts.items()\n",
    "               if len(context) > 1]\n",
    "contexts = dict([(term, contexts[term]) for term in nz_contexts])\n",
    "print(len(nz_contexts), 'nonzero contexts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rt\n",
      "[('yes@1', 0.018047454989163745), ('i@2', 0.24309157328634765), ('i@1', 0.8709649191368568)]\n"
     ]
    }
   ],
   "source": [
    "# e.g., what are three context features for the term \"rt\"?\n",
    "print(list(contexts.keys())[0])\n",
    "print(list(list(contexts.values())[0].items())[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a@-1' 'a@-2' 'a@1' 'a@2' 'aaron@-1' 'aaron@-2' 'aaron@1' 'aaron@2'\n",
      " 'ab@-1' 'ab@-2']\n",
      "  (0, 0)\t0.000608391440993\n",
      "  (0, 1)\t0.00184155775432\n",
      "  (0, 2)\t0.0296784604665\n",
      "  (0, 3)\t0.023081968924\n",
      "  (0, 24)\t0.000772453342136\n",
      "  (0, 36)\t0.00142439996922\n",
      "  (0, 85)\t0.0024285643445\n",
      "  (0, 113)\t0.00127100472844\n",
      "  (0, 120)\t0.00177305816505\n",
      "  (0, 137)\t0.00150039652435\n",
      "  (0, 145)\t0.00102174921021\n",
      "  (0, 152)\t0.00260173305892\n",
      "  (0, 156)\t0.00144728974486\n",
      "  (0, 161)\t0.00140347229238\n",
      "  (0, 185)\t0.00826629566769\n",
      "  (0, 201)\t0.00457615712315\n",
      "  (0, 208)\t0.0113951997537\n",
      "  (0, 216)\t0.00260173305892\n",
      "  (0, 241)\t0.00140347229238\n",
      "  (0, 251)\t0.00686423568472\n",
      "  (0, 264)\t0.00209241574335\n",
      "  (0, 265)\t0.00228807856157\n",
      "  (0, 270)\t0.00844293530641\n",
      "  (0, 271)\t0.00381327693678\n",
      "  (0, 279)\t0.000975855587642\n",
      "  :\t:\n",
      "  (0, 15466)\t0.0136718731665\n",
      "  (0, 15467)\t0.00928134083236\n",
      "  (0, 15486)\t0.0180474549892\n",
      "  (0, 15487)\t0.00231672663195\n",
      "  (0, 15490)\t0.00381301418531\n",
      "  (0, 15506)\t0.0024285643445\n",
      "  (0, 15511)\t0.00177305816505\n",
      "  (0, 15514)\t0.00170774020943\n",
      "  (0, 15515)\t0.00177305816505\n",
      "  (0, 15518)\t0.00260173305892\n",
      "  (0, 15522)\t0.00992462458881\n",
      "  (0, 15523)\t0.00133463023949\n",
      "  (0, 15526)\t0.00228807856157\n",
      "  (0, 15532)\t0.00062796140011\n",
      "  (0, 15534)\t0.0324731497618\n",
      "  (0, 15535)\t0.0578393968624\n",
      "  (0, 15538)\t0.0037217342208\n",
      "  (0, 15542)\t0.00185342685045\n",
      "  (0, 15546)\t0.00535629671489\n",
      "  (0, 15547)\t0.00230914580935\n",
      "  (0, 15559)\t0.00129419048958\n",
      "  (0, 15563)\t0.00165325913354\n",
      "  (0, 15566)\t0.00227185868819\n",
      "  (0, 15567)\t0.0011467757785\n",
      "  (0, 15582)\t0.00546002896928\n"
     ]
    }
   ],
   "source": [
    "# Transform context dicts to a sparse vector\n",
    "# for sklearn.\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "vec = DictVectorizer()\n",
    "X = vec.fit_transform(contexts.values())\n",
    "names = np.array(vec.get_feature_names())\n",
    "print(names[:10])\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "  (0, 0)\t0.00724304929286\n",
      "  (0, 1)\t0.00243602184957\n",
      "  (0, 2)\t0.0144216061026\n",
      "  (0, 3)\t0.00723148684548\n",
      "  (0, 5)\t0.0103247566851\n",
      "  (0, 6)\t0.00830357417341\n",
      "  (0, 34)\t0.0292170548963\n",
      "  (0, 145)\t0.00405472496588\n",
      "  (0, 168)\t0.00830357417341\n",
      "  (0, 195)\t0.00908004545032\n",
      "  (0, 224)\t0.00677702198663\n",
      "  (0, 245)\t0.0103247566851\n",
      "  (0, 271)\t0.00756633283537\n",
      "  (0, 279)\t0.00387260002237\n",
      "  (0, 347)\t0.00397254888256\n",
      "  (0, 394)\t0.00581154099097\n",
      "  (0, 395)\t0.0058612011343\n",
      "  (0, 396)\t0.0115587334938\n",
      "  (0, 397)\t0.0145227471674\n",
      "  (0, 437)\t0.00442936574452\n",
      "  (0, 450)\t0.00355215339765\n",
      "  (0, 451)\t0.00716303370885\n",
      "  (0, 455)\t0.00312683202546\n",
      "  (0, 457)\t0.00315557592013\n",
      "  (0, 472)\t0.00735516704871\n",
      "  :\t:\n",
      "  (0, 15339)\t0.00659377767189\n",
      "  (0, 15347)\t0.0173724037235\n",
      "  (0, 15385)\t0.00656081846393\n",
      "  (0, 15405)\t0.00908004545032\n",
      "  (0, 15413)\t0.00496134498333\n",
      "  (0, 15427)\t0.00908004545032\n",
      "  (0, 15430)\t0.011477652128\n",
      "  (0, 15434)\t0.008896229578\n",
      "  (0, 15485)\t0.00801508651213\n",
      "  (0, 15487)\t0.0045968664423\n",
      "  (0, 15504)\t0.00523943696338\n",
      "  (0, 15506)\t0.00481877567437\n",
      "  (0, 15521)\t0.00488672164748\n",
      "  (0, 15523)\t0.00529636675831\n",
      "  (0, 15531)\t0.00776129229457\n",
      "  (0, 15532)\t0.0323961493051\n",
      "  (0, 15533)\t0.0553304747958\n",
      "  (0, 15534)\t0.292428818484\n",
      "  (0, 15535)\t0.0573826835702\n",
      "  (0, 15539)\t0.00504387432127\n",
      "  (0, 15544)\t0.00609753524058\n",
      "  (0, 15546)\t0.0151828632964\n",
      "  (0, 15547)\t0.00305454967798\n",
      "  (0, 15551)\t0.0103247566851\n",
      "  (0, 15567)\t0.00455088228394\n",
      "you@1\n"
     ]
    }
   ],
   "source": [
    "# Which row of X is the word \"love\"?\n",
    "love_idx = list(contexts.keys()).index('love')\n",
    "print(love_idx)\n",
    "# What are the context feature values for love?\n",
    "print(X[love_idx])\n",
    "# Print a highly ranking feature.\n",
    "print(names[15534])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n",
       "    n_clusters=20, n_init=10, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's cluster!\n",
    "# http://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
    "from sklearn.cluster import KMeans\n",
    "num_clusters = 20\n",
    "kmeans = KMeans(num_clusters)\n",
    "kmeans.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 on@-1 you@2 on@-2 i@-2 i@1\n",
      "1 i@-2 m@-1 i@2 i@1 m@-2\n",
      "2 and@1 the@-2 i@1 the@-1 a@-2\n",
      "3 i@-1 i@-2 rt@-2 a@1 you@1\n",
      "4 in@1 on@1 the@2 i@-2 my@2\n",
      "5 i@1 i@-2 the@-1 a@-2 to@-2\n",
      "6 the@-1 in@-2 i@2 i@1 on@-2\n",
      "7 t@1 i@-1 you@-1 rt@-2 even@2\n",
      "8 a@-1 the@-1 i@2 i@1 and@1\n",
      "9 to@-1 i@-2 i@-1 a@1 the@1\n",
      "10 this@-1 i@1 i@2 a@-1 the@-1\n",
      "11 my@-1 i@1 i@2 of@-2 and@1\n",
      "12 i@2 i@1 i@-2 but@1 to@-2\n",
      "13 up@1 i@-2 i@-1 i@2 and@-1\n",
      "14 rt@-1 i@2 i@1 s@1 is@1\n",
      "15 i@1 rt@-1 m@2 i@2 the@-2\n",
      "16 me@1 t@-1 i@-2 i@-1 to@-1\n",
      "17 for@1 the@2 i@-2 a@-2 a@-1\n",
      "18 of@1 the@-1 the@2 my@2 i@-2\n",
      "19 to@1 i@-2 i@-1 the@2 be@2\n"
     ]
    }
   ],
   "source": [
    "# Let's print out the top features for each mean vector.\n",
    "# This is swamped by common terms\n",
    "for i in range(num_clusters):\n",
    "    print(i, ' '.join(names[np.argsort(\n",
    "        kmeans.cluster_centers_[i])[::-1][:5]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "distance from term \"love\" to each cluster:\n",
      "[ 1.02299852  0.98543462  0.99026422  0.5854914   0.98713006  0.97795726\n",
      "  1.02537547  1.09786564  1.02773076  0.97479063  1.01424504  1.04027972\n",
      "  0.98008083  0.98354497  1.00036492  1.03436615  0.91330911  1.00144954\n",
      "  1.02748702  0.99320934]\n",
      "closest cluster to \"love\":\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# .transform will compute the distance from each context to each cluster.\n",
    "distances = kmeans.transform(X)\n",
    "# e.g., what is the distance from the word \"love\" to each cluster?\n",
    "print('distance from term \"love\" to each cluster:')\n",
    "print(distances[love_idx])\n",
    "# what is the closest cluster for the word \"love\"?\n",
    "print('closest cluster to \"love\":')\n",
    "print(np.argmin(distances[love_idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 soundcloud tv friday itunes tour holiday earth bbc repeat \n",
      "\n",
      "1 sorry glad getting crying joking a gonna shaking done \n",
      "\n",
      "2 day and person one time girlfriend that of ins \n",
      "\n",
      "3 love am just ll guess think hope hate have \n",
      "\n",
      "4 participate lookin sacked stuck working back involved debate born \n",
      "\n",
      "5 that the this but like for on me a \n",
      "\n",
      "6 world gym streets uk best area worst most first \n",
      "\n",
      "7 didn wasn wouldn ain haven couldn won doesn shouldn \n",
      "\n",
      "8 few great bit good little playlist blessing problem job \n",
      "\n",
      "9 see say win get do go make watch sleep \n",
      "\n",
      "10 is morning tweet thread faithfulness year month shit guy \n",
      "\n",
      "11 heart favorite phone mom brain homie spotify mind boyfriend \n",
      "\n",
      "12 how the and this gray so baffled every easier \n",
      "\n",
      "13 woke fucked messed shut growing wrapped pulled heads picking \n",
      "\n",
      "14 gray dear i hi tracklist if goodnight awww this \n",
      "\n",
      "15 but when omg and yeah yes if hello because \n",
      "\n",
      "16 follow get ask make see help leave do told \n",
      "\n",
      "17 thankful thanks apologize plans pay looking bloom voted praying \n",
      "\n",
      "18 epitome part one afraid proud highlights none instead height \n",
      "\n",
      "19 supposed trying want used decided seem close committed due \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Finally, we'll print the words that are closest\n",
    "# to the mean of each cluster.\n",
    "terms = np.array(list(contexts.keys()))\n",
    "for i in range(distances.shape[1]):\n",
    "    print(i, ' '.join(terms[np.argsort(distances[:,i])[1:10]]), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clearly, interpreting these results requires a bit of investigation.\n",
    "\n",
    "As the number of tweets increases, we expect these clusters to become more coherent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How does error decrease with number of cluster?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-3610.7138169426016"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kmeans.score(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=5 score=3745.59\n",
      "k=10 score=3673.62\n",
      "k=20 score=3619.19\n",
      "k=50 score=3533.6\n",
      "k=100 score=3456.81\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nq7Z5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x116b54860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "scores = []\n",
    "num_cluster_options = [5,10,20,50,100]\n",
    "\n",
    "for num_clusters in num_cluster_options:\n",
    "    kmeans = KMeans(num_clusters, n_init=10, max_iter=10)\n",
    "    kmeans.fit(X)\n",
    "    score = -1 * kmeans.score(X)\n",
    "    scores.append(score)\n",
    "    print('k=%d score=%g' % (num_clusters, score))\n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(num_cluster_options, scores, 'bo-')\n",
    "plt.xlabel('num clusters')\n",
    "plt.ylabel('error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** How does error vary by initalization? **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score=3621.13\n",
      "score=3614.67\n",
      "score=3628.88\n",
      "score=3633.02\n",
      "score=3628.3\n",
      "score=3629.97\n",
      "score=3633.27\n",
      "score=3640.09\n",
      "score=3637.93\n",
      "score=3635.66\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY8AAAEKCAYAAADq59mMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDzMzK9v/A9rXTp0NEa6KAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1169e3780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "for i in range(10):\n",
    "    kmeans = KMeans(20, n_init=1,\n",
    "                    max_iter=100,\n",
    "                    init='random')\n",
    "    kmeans.fit(X)\n",
    "    score = -1 * kmeans.score(X)\n",
    "    scores.append(score)\n",
    "    print('score=%g' % (score))\n",
    "     \n",
    "    \n",
    "plt.figure()\n",
    "plt.plot(range(10), sorted(scores), 'bo-')\n",
    "plt.xlabel('sample')\n",
    "plt.ylabel('error')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
